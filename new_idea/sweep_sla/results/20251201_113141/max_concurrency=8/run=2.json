{
    "date": "20251201-113408",
    "endpoint_type": "vllm",
    "backend": "vllm",
    "label": null,
    "model_id": "../../models/llama3-3b",
    "tokenizer_id": "../../models/llama3-3b",
    "num_prompts": 10,
    "request_rate": "inf",
    "burstiness": 1.0,
    "max_concurrency": 8,
    "duration": 2.7189121060073376,
    "completed": 10,
    "failed": 0,
    "total_input_tokens": 1369,
    "total_output_tokens": 1094,
    "request_throughput": 3.6779416215424408,
    "request_goodput": null,
    "output_throughput": 402.36681339674305,
    "total_token_throughput": 905.8770213859032,
    "max_output_tokens_per_s": 617.0,
    "max_concurrent_requests": 10,
    "mean_ttft_ms": 32.87369741592556,
    "median_ttft_ms": 38.09397807344794,
    "std_ttft_ms": 9.781954025148002,
    "p99_ttft_ms": 40.81595950759947,
    "mean_tpot_ms": 3.9119034951002374,
    "median_tpot_ms": 3.8231191283557564,
    "std_tpot_ms": 0.27231776875193936,
    "p99_tpot_ms": 4.442996963392943,
    "mean_itl_ms": 3.6519394740307654,
    "median_itl_ms": 3.6129708169028163,
    "std_itl_ms": 0.5328770168909178,
    "p99_itl_ms": 4.155016252771021,
    "mean_e2el_ms": 428.74359460547566,
    "median_e2el_ms": 61.50870048440993,
    "std_e2el_ms": 795.7533801645471,
    "p99_e2el_ms": 2537.98347523436,
    "run_number": 2
}