[
    {
        "date": "20251201-113211",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 65536,
        "duration": 2.725443923845887,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.669127041105638,
        "request_goodput": null,
        "output_throughput": 398.83410936818285,
        "total_token_throughput": 901.1376012955448,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 36.80298731196672,
        "median_ttft_ms": 37.635428016074,
        "std_ttft_ms": 8.480478848173952,
        "p99_ttft_ms": 45.71552291512489,
        "mean_tpot_ms": 6.04625123024732,
        "median_tpot_ms": 3.8280201610177755,
        "std_tpot_ms": 5.021231559152159,
        "p99_tpot_ms": 17.49791977880522,
        "mean_itl_ms": 3.6843255561747923,
        "median_itl_ms": 3.6152310203760862,
        "std_itl_ms": 0.8957721869665177,
        "p99_itl_ms": 4.238887932151556,
        "mean_e2el_ms": 433.6045655887574,
        "median_e2el_ms": 71.36281591374427,
        "std_e2el_ms": 795.4224301455531,
        "p99_e2el_ms": 2542.5559047167194,
        "run_number": 0
    },
    {
        "date": "20251201-113222",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 65536,
        "duration": 2.7250340620521456,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6696789002590613,
        "request_goodput": null,
        "output_throughput": 398.89409645815994,
        "total_token_throughput": 901.2731379036254,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 42.545406660065055,
        "median_ttft_ms": 45.20696902181953,
        "std_ttft_ms": 8.19567092350781,
        "p99_ttft_ms": 47.21390079939738,
        "mean_tpot_ms": 3.699298599198058,
        "median_tpot_ms": 3.788228239864111,
        "std_tpot_ms": 0.14651500578423796,
        "p99_tpot_ms": 3.8401713350093836,
        "mean_itl_ms": 3.6499072743982715,
        "median_itl_ms": 3.6192298866808414,
        "std_itl_ms": 0.7371604819020423,
        "p99_itl_ms": 4.0261816047132015,
        "mean_e2el_ms": 435.6402861420065,
        "median_e2el_ms": 70.01458597369492,
        "std_e2el_ms": 795.1452577698162,
        "p99_e2el_ms": 2544.2201944487174,
        "run_number": 1
    },
    {
        "date": "20251201-113232",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 65536,
        "duration": 2.7119724310468882,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.687353118165642,
        "request_goodput": null,
        "output_throughput": 400.8152839446053,
        "total_token_throughput": 905.6139258214816,
        "max_output_tokens_per_s": 612.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 39.033411839045584,
        "median_ttft_ms": 40.530208963900805,
        "std_ttft_ms": 6.422392061413254,
        "p99_ttft_ms": 43.51645874325187,
        "mean_tpot_ms": 3.613771079071116,
        "median_tpot_ms": 3.699418157339096,
        "std_tpot_ms": 0.219947114704851,
        "p99_tpot_ms": 3.774885197604435,
        "mean_itl_ms": 3.6286599832494417,
        "median_itl_ms": 3.606701036915183,
        "std_itl_ms": 0.5659819736027122,
        "p99_itl_ms": 4.0254198014736176,
        "mean_e2el_ms": 429.8398149665445,
        "median_e2el_ms": 65.74449047911912,
        "std_e2el_ms": 792.2627757295706,
        "p99_e2el_ms": 2531.006546851713,
        "run_number": 2
    },
    {
        "date": "20251201-113243",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 2,
        "duration": 3.142515828134492,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.182163765245489,
        "request_goodput": null,
        "output_throughput": 345.9012012821846,
        "total_token_throughput": 781.539420744292,
        "max_output_tokens_per_s": 492.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 13.632723316550255,
        "median_ttft_ms": 13.325906591489911,
        "std_ttft_ms": 2.2799238886753606,
        "p99_ttft_ms": 17.544709034264088,
        "mean_tpot_ms": 3.640744379539738,
        "median_tpot_ms": 3.6127015633659587,
        "std_tpot_ms": 0.0849107025660907,
        "p99_tpot_ms": 3.803810255602002,
        "mean_itl_ms": 3.601102822113474,
        "median_itl_ms": 3.5883409436792135,
        "std_itl_ms": 0.2484066118486161,
        "p99_itl_ms": 4.009263105690479,
        "mean_e2el_ms": 401.47114023566246,
        "median_e2el_ms": 37.56086283829063,
        "std_e2el_ms": 793.7784159690466,
        "p99_e2el_ms": 2508.973681130447,
        "run_number": 0
    },
    {
        "date": "20251201-113254",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 2,
        "duration": 3.140227337135002,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.1844828180890676,
        "request_goodput": null,
        "output_throughput": 346.15328232628167,
        "total_token_throughput": 782.108980122675,
        "max_output_tokens_per_s": 491.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 15.375538123771548,
        "median_ttft_ms": 15.26511600241065,
        "std_ttft_ms": 2.2510953235632774,
        "p99_ttft_ms": 18.071869774721563,
        "mean_tpot_ms": 3.6390702432157864,
        "median_tpot_ms": 3.605135263422051,
        "std_tpot_ms": 0.0784243007822286,
        "p99_tpot_ms": 3.8115039203936854,
        "mean_itl_ms": 3.6018665626164297,
        "median_itl_ms": 3.5877199843525887,
        "std_itl_ms": 0.2511718420570596,
        "p99_itl_ms": 4.041487956419587,
        "mean_e2el_ms": 403.2961309887469,
        "median_e2el_ms": 38.747297949157655,
        "std_e2el_ms": 791.9521181470831,
        "p99_e2el_ms": 2504.807908309158,
        "run_number": 1
    },
    {
        "date": "20251201-113305",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 2,
        "duration": 3.136064824881032,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.1887095957524902,
        "request_goodput": null,
        "output_throughput": 346.6127330582957,
        "total_token_throughput": 783.1470767168116,
        "max_output_tokens_per_s": 492.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 14.016659022308886,
        "median_ttft_ms": 13.463206007145345,
        "std_ttft_ms": 2.726774986696856,
        "p99_ttft_ms": 18.04281019140035,
        "mean_tpot_ms": 3.6037588262053597,
        "median_tpot_ms": 3.6023096149988674,
        "std_tpot_ms": 0.027506283319663913,
        "p99_tpot_ms": 3.6572067718952894,
        "mean_itl_ms": 3.598193135614072,
        "median_itl_ms": 3.583109937608242,
        "std_itl_ms": 0.24504276468896835,
        "p99_itl_ms": 4.01942596770823,
        "mean_e2el_ms": 401.54166573192924,
        "median_e2el_ms": 36.502922885119915,
        "std_e2el_ms": 792.0439511826901,
        "p99_e2el_ms": 2503.072639247403,
        "run_number": 2
    },
    {
        "date": "20251201-113316",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 4,
        "duration": 2.7400055308826268,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6496276694663243,
        "request_goodput": null,
        "output_throughput": 396.71452767098947,
        "total_token_throughput": 896.3485556209292,
        "max_output_tokens_per_s": 605.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 16.56181961297989,
        "median_ttft_ms": 16.432682052254677,
        "std_ttft_ms": 1.764817311736674,
        "p99_ttft_ms": 19.45839755004272,
        "mean_tpot_ms": 3.7893020459205853,
        "median_tpot_ms": 3.7058147653523417,
        "std_tpot_ms": 0.16280012378393335,
        "p99_tpot_ms": 4.13182131620124,
        "mean_itl_ms": 3.662311562363788,
        "median_itl_ms": 3.613261040300131,
        "std_itl_ms": 0.42529405171626905,
        "p99_itl_ms": 5.4440126195549965,
        "mean_e2el_ms": 410.9924888238311,
        "median_e2el_ms": 41.203858447261155,
        "std_e2el_ms": 796.735819677838,
        "p99_e2el_ms": 2521.1769831436686,
        "run_number": 0
    },
    {
        "date": "20251201-113326",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 4,
        "duration": 2.7369939398486167,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.653643456935495,
        "request_goodput": null,
        "output_throughput": 397.1510437688883,
        "total_token_throughput": 897.3348330233575,
        "max_output_tokens_per_s": 606.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 16.026543360203505,
        "median_ttft_ms": 16.215496929362416,
        "std_ttft_ms": 2.4896625882159267,
        "p99_ttft_ms": 19.737481933552772,
        "mean_tpot_ms": 3.7962607492257368,
        "median_tpot_ms": 3.778436117484665,
        "std_tpot_ms": 0.1317955022565071,
        "p99_tpot_ms": 4.061286183074117,
        "mean_itl_ms": 3.6662064186585313,
        "median_itl_ms": 3.6174810957163572,
        "std_itl_ms": 0.4248783949097614,
        "p99_itl_ms": 5.312003269791603,
        "mean_e2el_ms": 410.8765825862065,
        "median_e2el_ms": 41.48537339642644,
        "std_e2el_ms": 796.2037798093829,
        "p99_e2el_ms": 2519.2664481233805,
        "run_number": 1
    },
    {
        "date": "20251201-113337",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 4,
        "duration": 2.73036493989639,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.662514066848322,
        "request_goodput": null,
        "output_throughput": 398.11527906641254,
        "total_token_throughput": 899.5134548179478,
        "max_output_tokens_per_s": 607.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 14.894208614714444,
        "median_ttft_ms": 15.72094694711268,
        "std_ttft_ms": 2.681381115162532,
        "p99_ttft_ms": 18.195024949964136,
        "mean_tpot_ms": 3.7509213802970103,
        "median_tpot_ms": 3.69209637310491,
        "std_tpot_ms": 0.13740523669854593,
        "p99_tpot_ms": 4.048644653055817,
        "mean_itl_ms": 3.6529778918388023,
        "median_itl_ms": 3.6074998788535595,
        "std_itl_ms": 0.3968094718015128,
        "p99_itl_ms": 5.491261500865221,
        "mean_e2el_ms": 408.31955247558653,
        "median_e2el_ms": 37.347592995502055,
        "std_e2el_ms": 794.8458978501059,
        "p99_e2el_ms": 2513.2399562513456,
        "run_number": 2
    },
    {
        "date": "20251201-113347",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 8,
        "duration": 2.717371796956286,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1094,
        "request_throughput": 3.680026417879566,
        "request_goodput": null,
        "output_throughput": 402.59489011602454,
        "total_token_throughput": 906.3905067237371,
        "max_output_tokens_per_s": 617.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 35.778189823031425,
        "median_ttft_ms": 42.738638585433364,
        "std_ttft_ms": 12.026924921700335,
        "p99_ttft_ms": 45.80891372868791,
        "mean_tpot_ms": 3.9555010970100364,
        "median_tpot_ms": 3.842539052129723,
        "std_tpot_ms": 0.31717907854763155,
        "p99_tpot_ms": 4.574648815672844,
        "mean_itl_ms": 3.6500416078769717,
        "median_itl_ms": 3.6045946180820465,
        "std_itl_ms": 0.6880477928045022,
        "p99_itl_ms": 4.402357432991269,
        "mean_e2el_ms": 431.4424051903188,
        "median_e2el_ms": 64.39104536548257,
        "std_e2el_ms": 794.1667613229122,
        "p99_e2el_ms": 2536.3635897520003,
        "run_number": 0
    },
    {
        "date": "20251201-113358",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 8,
        "duration": 2.7163746969308704,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1094,
        "request_throughput": 3.681377245671823,
        "request_goodput": null,
        "output_throughput": 402.7426706764974,
        "total_token_throughput": 906.7232156089699,
        "max_output_tokens_per_s": 619.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 30.315596982836723,
        "median_ttft_ms": 35.34948197193444,
        "std_ttft_ms": 9.340697361467512,
        "p99_ttft_ms": 38.30056686885655,
        "mean_tpot_ms": 3.600183322742301,
        "median_tpot_ms": 3.6885233712382615,
        "std_tpot_ms": 0.32856911819780604,
        "p99_tpot_ms": 3.879914900287986,
        "mean_itl_ms": 3.641213164742129,
        "median_itl_ms": 3.613450098782778,
        "std_itl_ms": 0.4595139469679245,
        "p99_itl_ms": 4.044483958277852,
        "mean_e2el_ms": 425.0228120945394,
        "median_e2el_ms": 58.20208939258009,
        "std_e2el_ms": 795.6510206718416,
        "p99_e2el_ms": 2534.870317145251,
        "run_number": 1
    },
    {
        "date": "20251201-113408",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 8,
        "duration": 2.7189121060073376,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1094,
        "request_throughput": 3.6779416215424408,
        "request_goodput": null,
        "output_throughput": 402.36681339674305,
        "total_token_throughput": 905.8770213859032,
        "max_output_tokens_per_s": 617.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 32.87369741592556,
        "median_ttft_ms": 38.09397807344794,
        "std_ttft_ms": 9.781954025148002,
        "p99_ttft_ms": 40.81595950759947,
        "mean_tpot_ms": 3.9119034951002374,
        "median_tpot_ms": 3.8231191283557564,
        "std_tpot_ms": 0.27231776875193936,
        "p99_tpot_ms": 4.442996963392943,
        "mean_itl_ms": 3.6519394740307654,
        "median_itl_ms": 3.6129708169028163,
        "std_itl_ms": 0.5328770168909178,
        "p99_itl_ms": 4.155016252771021,
        "mean_e2el_ms": 428.74359460547566,
        "median_e2el_ms": 61.50870048440993,
        "std_e2el_ms": 795.7533801645471,
        "p99_e2el_ms": 2537.98347523436,
        "run_number": 2
    },
    {
        "date": "20251201-113419",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 16,
        "duration": 2.7271511959843338,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.666830066013489,
        "request_goodput": null,
        "output_throughput": 398.58442817566623,
        "total_token_throughput": 900.5734642129129,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 40.82377862650901,
        "median_ttft_ms": 45.85091792978346,
        "std_ttft_ms": 10.250558571635764,
        "p99_ttft_ms": 46.91296506440267,
        "mean_tpot_ms": 6.865330844519043,
        "median_tpot_ms": 3.880640398710966,
        "std_tpot_ms": 7.515656561847704,
        "p99_tpot_ms": 23.99005457603682,
        "mean_itl_ms": 3.6772347745868683,
        "median_itl_ms": 3.6208010278642178,
        "std_itl_ms": 0.943414538446115,
        "p99_itl_ms": 4.193650223314763,
        "mean_e2el_ms": 436.8618397973478,
        "median_e2el_ms": 72.20908557064831,
        "std_e2el_ms": 795.6850685472074,
        "p99_e2el_ms": 2546.59855350852,
        "run_number": 0
    },
    {
        "date": "20251201-113429",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 16,
        "duration": 2.7192956060171127,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6774229244781376,
        "request_goodput": null,
        "output_throughput": 399.7358718907735,
        "total_token_throughput": 903.1750702518306,
        "max_output_tokens_per_s": 611.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.32827289868146,
        "median_ttft_ms": 42.922668042592704,
        "std_ttft_ms": 6.427825748579539,
        "p99_ttft_ms": 45.514038018882275,
        "mean_tpot_ms": 3.5800257157816744,
        "median_tpot_ms": 3.6191984400674313,
        "std_tpot_ms": 0.2644641285430459,
        "p99_tpot_ms": 3.772730934446683,
        "mean_itl_ms": 3.6328658848540893,
        "median_itl_ms": 3.61111992970109,
        "std_itl_ms": 0.5784232159430589,
        "p99_itl_ms": 4.04297759756446,
        "mean_e2el_ms": 432.5876447139308,
        "median_e2el_ms": 67.64830555766821,
        "std_e2el_ms": 793.8939430164806,
        "p99_e2el_ms": 2538.2579857530072,
        "run_number": 1
    },
    {
        "date": "20251201-113440",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 16,
        "duration": 2.7263441861141473,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6679154638406017,
        "request_goodput": null,
        "output_throughput": 398.7024109194734,
        "total_token_throughput": 900.8400379192517,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 43.13319080974907,
        "median_ttft_ms": 44.999624020420015,
        "std_ttft_ms": 6.245722512769554,
        "p99_ttft_ms": 47.2116543748416,
        "mean_tpot_ms": 3.6919770095357816,
        "median_tpot_ms": 3.7929939336980842,
        "std_tpot_ms": 0.2145513543099569,
        "p99_tpot_ms": 3.8654836346395314,
        "mean_itl_ms": 3.6473375656049676,
        "median_itl_ms": 3.620469942688942,
        "std_itl_ms": 0.574183111211766,
        "p99_itl_ms": 4.093592027202249,
        "mean_e2el_ms": 435.9511406160891,
        "median_e2el_ms": 70.23170660249889,
        "std_e2el_ms": 795.4604277132532,
        "p99_e2el_ms": 2545.320288713556,
        "run_number": 2
    },
    {
        "date": "20251201-113450",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 32,
        "duration": 2.7208879839163274,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6752707421664734,
        "request_goodput": null,
        "output_throughput": 399.5019296734957,
        "total_token_throughput": 902.6464942760858,
        "max_output_tokens_per_s": 611.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 38.5910589247942,
        "median_ttft_ms": 40.07212305441499,
        "std_ttft_ms": 6.638988733562269,
        "p99_ttft_ms": 42.295640816446394,
        "mean_tpot_ms": 3.6248385646172916,
        "median_tpot_ms": 3.668766375631094,
        "std_tpot_ms": 0.15835621447909495,
        "p99_tpot_ms": 3.7796553469416936,
        "mean_itl_ms": 3.6408761427577794,
        "median_itl_ms": 3.6195300053805113,
        "std_itl_ms": 0.5635373295475218,
        "p99_itl_ms": 3.9942607190459967,
        "mean_e2el_ms": 430.7131334906444,
        "median_e2el_ms": 65.83042547572404,
        "std_e2el_ms": 795.3885436501615,
        "p99_e2el_ms": 2540.283931361046,
        "run_number": 0
    },
    {
        "date": "20251201-113501",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 32,
        "duration": 2.724831895204261,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6699511693180518,
        "request_goodput": null,
        "output_throughput": 398.9236921048722,
        "total_token_throughput": 901.3400071845134,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.04375126771629,
        "median_ttft_ms": 42.40724793635309,
        "std_ttft_ms": 6.254564629388256,
        "p99_ttft_ms": 45.489135335665196,
        "mean_tpot_ms": 3.6499009477221684,
        "median_tpot_ms": 3.736116411164403,
        "std_tpot_ms": 0.25327973438801715,
        "p99_tpot_ms": 3.8475380605086684,
        "mean_itl_ms": 3.6463839496583605,
        "median_itl_ms": 3.619150025770068,
        "std_itl_ms": 0.5743947697737858,
        "p99_itl_ms": 4.076003581285477,
        "mean_e2el_ms": 433.75897565856576,
        "median_e2el_ms": 68.19977553095669,
        "std_e2el_ms": 795.4525734106112,
        "p99_e2el_ms": 2543.0546285747555,
        "run_number": 1
    },
    {
        "date": "20251201-113512",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 32,
        "duration": 2.7298500949982554,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.663204810521433,
        "request_goodput": null,
        "output_throughput": 398.1903629036798,
        "total_token_throughput": 899.683101464064,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.14831129554659,
        "median_ttft_ms": 42.55741345696151,
        "std_ttft_ms": 6.171747853694898,
        "p99_ttft_ms": 45.563424127176404,
        "mean_tpot_ms": 3.6257539127895613,
        "median_tpot_ms": 3.729956364259124,
        "std_tpot_ms": 0.3384239232782509,
        "p99_tpot_ms": 3.8814545343630016,
        "mean_itl_ms": 3.6529766706128917,
        "median_itl_ms": 3.6278010811656713,
        "std_itl_ms": 0.5729865048035776,
        "p99_itl_ms": 4.106325451284647,
        "mean_e2el_ms": 434.57360879983753,
        "median_e2el_ms": 68.50838591344655,
        "std_e2el_ms": 796.9343353121468,
        "p99_e2el_ms": 2547.835844329093,
        "run_number": 2
    },
    {
        "date": "20251201-113522",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 64,
        "duration": 2.7292648751754314,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.663990289457421,
        "request_goodput": null,
        "output_throughput": 398.2757444640216,
        "total_token_throughput": 899.8760150907425,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.573320142924786,
        "median_ttft_ms": 43.06371312122792,
        "std_ttft_ms": 6.437174128039121,
        "p99_ttft_ms": 45.67770882509649,
        "mean_tpot_ms": 3.6347893107926055,
        "median_tpot_ms": 3.7626424338668585,
        "std_tpot_ms": 0.2862074569745143,
        "p99_tpot_ms": 3.8260294695695243,
        "mean_itl_ms": 3.651638796765741,
        "median_itl_ms": 3.6257097963243723,
        "std_itl_ms": 0.5773904816066162,
        "p99_itl_ms": 4.140839613974094,
        "mean_e2el_ms": 434.85449054278433,
        "median_e2el_ms": 68.97724058944732,
        "std_e2el_ms": 796.7560216050614,
        "p99_e2el_ms": 2547.6144340890464,
        "run_number": 0
    },
    {
        "date": "20251201-113533",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 64,
        "duration": 2.7215435029938817,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6743855055042567,
        "request_goodput": null,
        "output_throughput": 399.40570444831275,
        "total_token_throughput": 902.4290801518455,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 37.96225639525801,
        "median_ttft_ms": 39.85519357956946,
        "std_ttft_ms": 6.398863701235414,
        "p99_ttft_ms": 42.095156838186085,
        "mean_tpot_ms": 3.729279437452635,
        "median_tpot_ms": 3.8088340167457067,
        "std_tpot_ms": 0.2587102702155559,
        "p99_tpot_ms": 3.961166772060096,
        "mean_itl_ms": 3.653439509179945,
        "median_itl_ms": 3.6204711068421602,
        "std_itl_ms": 0.551107567557542,
        "p99_itl_ms": 4.3336250353604555,
        "mean_e2el_ms": 431.43755758646876,
        "median_e2el_ms": 66.25014054588974,
        "std_e2el_ms": 795.6973327551057,
        "p99_e2el_ms": 2541.1509633762766,
        "run_number": 1
    },
    {
        "date": "20251201-113543",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 64,
        "duration": 2.7292451930698007,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6640167125300307,
        "request_goodput": null,
        "output_throughput": 398.2786166520143,
        "total_token_throughput": 899.8825045973755,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 42.00287153944373,
        "median_ttft_ms": 43.14704390708357,
        "std_ttft_ms": 6.372181975599152,
        "p99_ttft_ms": 47.09102112101391,
        "mean_tpot_ms": 3.588376464948068,
        "median_tpot_ms": 3.693912411108613,
        "std_tpot_ms": 0.31379177206253567,
        "p99_tpot_ms": 3.7962894589687157,
        "mean_itl_ms": 3.648299138219949,
        "median_itl_ms": 3.6257600877434015,
        "std_itl_ms": 0.5732596211930997,
        "p99_itl_ms": 4.098712559789419,
        "mean_e2el_ms": 434.9243547767401,
        "median_e2el_ms": 68.94142541568726,
        "std_e2el_ms": 796.4913552326586,
        "p99_e2el_ms": 2547.042230679654,
        "run_number": 2
    },
    {
        "date": "20251201-113554",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 128,
        "duration": 2.717320450814441,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.680095955190997,
        "request_goodput": null,
        "output_throughput": 400.02643032926136,
        "total_token_throughput": 903.8315665949088,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 42.68309383187443,
        "median_ttft_ms": 44.324898975901306,
        "std_ttft_ms": 6.277060410315355,
        "p99_ttft_ms": 46.92465822445229,
        "mean_tpot_ms": 3.647864130889161,
        "median_tpot_ms": 3.6974024027585983,
        "std_tpot_ms": 0.13506534239074386,
        "p99_tpot_ms": 3.7813123385356713,
        "mean_itl_ms": 3.633711142024456,
        "median_itl_ms": 3.6016900558024645,
        "std_itl_ms": 0.569920814382513,
        "p99_itl_ms": 4.000593954697251,
        "mean_e2el_ms": 434.03350783046335,
        "median_e2el_ms": 68.95162153523415,
        "std_e2el_ms": 792.8740607375585,
        "p99_e2el_ms": 2536.2381735094827,
        "run_number": 0
    },
    {
        "date": "20251201-113604",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 128,
        "duration": 2.7289568029809743,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.664403917671583,
        "request_goodput": null,
        "output_throughput": 398.32070585090105,
        "total_token_throughput": 899.9776021801407,
        "max_output_tokens_per_s": 608.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 40.03952373750508,
        "median_ttft_ms": 35.11280694510788,
        "std_ttft_ms": 10.152308506031265,
        "p99_ttft_ms": 55.73488149559125,
        "mean_tpot_ms": 7.172910883590899,
        "median_tpot_ms": 3.819282151007352,
        "std_tpot_ms": 6.281275999204805,
        "p99_tpot_ms": 21.335328054614358,
        "mean_itl_ms": 3.7271666648376565,
        "median_itl_ms": 3.6157011054456234,
        "std_itl_ms": 1.414393422061907,
        "p99_itl_ms": 4.362350106239319,
        "mean_e2el_ms": 441.4550276240334,
        "median_e2el_ms": 78.95051664672792,
        "std_e2el_ms": 794.1768199406351,
        "p99_e2el_ms": 2547.3158648051326,
        "run_number": 1
    },
    {
        "date": "20251201-113615",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 128,
        "duration": 2.720087711000815,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6763520380453656,
        "request_goodput": null,
        "output_throughput": 399.6194665355313,
        "total_token_throughput": 902.9120605439418,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.79526031948626,
        "median_ttft_ms": 42.97236853744835,
        "std_ttft_ms": 6.118097825464478,
        "p99_ttft_ms": 46.64894612506032,
        "mean_tpot_ms": 3.576133046948638,
        "median_tpot_ms": 3.6273449586964954,
        "std_tpot_ms": 0.2774918984320384,
        "p99_tpot_ms": 3.769887822922789,
        "mean_itl_ms": 3.633227920074953,
        "median_itl_ms": 3.6104312166571617,
        "std_itl_ms": 0.5623751940470304,
        "p99_itl_ms": 4.082824410870671,
        "mean_e2el_ms": 433.09362032450736,
        "median_e2el_ms": 68.20584053639323,
        "std_e2el_ms": 793.8869930481289,
        "p99_e2el_ms": 2538.3825256768614,
        "run_number": 2
    },
    {
        "date": "20251201-113625",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 256,
        "duration": 2.7242746111005545,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6707019032711217,
        "request_goodput": null,
        "output_throughput": 399.00529688557094,
        "total_token_throughput": 901.5243874433875,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 42.61612768750638,
        "median_ttft_ms": 44.18897849973291,
        "std_ttft_ms": 6.49535581438822,
        "p99_ttft_ms": 46.987917649094015,
        "mean_tpot_ms": 3.703565814715097,
        "median_tpot_ms": 3.804132326686082,
        "std_tpot_ms": 0.19886846557704452,
        "p99_tpot_ms": 3.865573385885606,
        "mean_itl_ms": 3.6468318077245296,
        "median_itl_ms": 3.6168298684060574,
        "std_itl_ms": 0.5874257289087462,
        "p99_itl_ms": 4.17261715978384,
        "mean_e2el_ms": 435.3796404087916,
        "median_e2el_ms": 70.3401054488495,
        "std_e2el_ms": 794.7724137366346,
        "p99_e2el_ms": 2542.7313249045988,
        "run_number": 0
    },
    {
        "date": "20251201-113636",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 256,
        "duration": 2.719619540963322,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6769849051966585,
        "request_goodput": null,
        "output_throughput": 399.68825919487676,
        "total_token_throughput": 903.0674927162993,
        "max_output_tokens_per_s": 611.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 32.36163109540939,
        "median_ttft_ms": 26.972778025083244,
        "std_ttft_ms": 9.451581995278612,
        "p99_ttft_ms": 44.10401728004217,
        "mean_tpot_ms": 6.152915076204661,
        "median_tpot_ms": 3.7724058816416393,
        "std_tpot_ms": 5.307190509194158,
        "p99_tpot_ms": 18.257540745194994,
        "mean_itl_ms": 3.7015790176839882,
        "median_itl_ms": 3.6190608516335487,
        "std_itl_ms": 1.0633099047942298,
        "p99_itl_ms": 4.11409473977983,
        "mean_e2el_ms": 431.02140130940825,
        "median_e2el_ms": 69.52388549689204,
        "std_e2el_ms": 794.7433945891485,
        "p99_e2el_ms": 2538.3842623955575,
        "run_number": 1
    },
    {
        "date": "20251201-113646",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 256,
        "duration": 2.7223959600087255,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.673234954392141,
        "request_goodput": null,
        "output_throughput": 399.2806395424257,
        "total_token_throughput": 902.1465047987099,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.93414063192904,
        "median_ttft_ms": 43.73170901089907,
        "std_ttft_ms": 6.443526220628207,
        "p99_ttft_ms": 45.72379122721031,
        "mean_tpot_ms": 3.699943214984918,
        "median_tpot_ms": 3.798223830399518,
        "std_tpot_ms": 0.17189304037775838,
        "p99_tpot_ms": 3.8528389546813235,
        "mean_itl_ms": 3.6447436549634213,
        "median_itl_ms": 3.615981200709939,
        "std_itl_ms": 0.566786362853215,
        "p99_itl_ms": 4.303737208247185,
        "mean_e2el_ms": 434.47273820638657,
        "median_e2el_ms": 69.31822001934052,
        "std_e2el_ms": 794.6606017203433,
        "p99_e2el_ms": 2541.558173426893,
        "run_number": 2
    },
    {
        "date": "20251201-113657",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 512,
        "duration": 2.722067649010569,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.67367798652427,
        "request_goodput": null,
        "output_throughput": 399.32879713518815,
        "total_token_throughput": 902.2553134903608,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 40.064312098547816,
        "median_ttft_ms": 41.90239298623055,
        "std_ttft_ms": 6.444151320754265,
        "p99_ttft_ms": 44.32733396301046,
        "mean_tpot_ms": 3.6306788964236407,
        "median_tpot_ms": 3.754964377731085,
        "std_tpot_ms": 0.2888559611490618,
        "p99_tpot_ms": 3.83070641104132,
        "mean_itl_ms": 3.6442379439950074,
        "median_itl_ms": 3.6173099651932716,
        "std_itl_ms": 0.5707889904016651,
        "p99_itl_ms": 4.168970650061965,
        "mean_e2el_ms": 432.548420666717,
        "median_e2el_ms": 67.24343937821686,
        "std_e2el_ms": 795.1433546534842,
        "p99_e2el_ms": 2541.1332478234544,
        "run_number": 0
    },
    {
        "date": "20251201-113708",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 512,
        "duration": 2.7073695580475032,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6936220880062582,
        "request_goodput": null,
        "output_throughput": 401.4967209662803,
        "total_token_throughput": 907.153584814337,
        "max_output_tokens_per_s": 613.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.64891068357974,
        "median_ttft_ms": 43.353223940357566,
        "std_ttft_ms": 6.2316097352807605,
        "p99_ttft_ms": 45.46979684615508,
        "mean_tpot_ms": 3.572742253992715,
        "median_tpot_ms": 3.5948886674501606,
        "std_tpot_ms": 0.1704772775737632,
        "p99_tpot_ms": 3.7282124332841016,
        "mean_itl_ms": 3.6096725169268327,
        "median_itl_ms": 3.591859946027398,
        "std_itl_ms": 0.5638746502983378,
        "p99_itl_ms": 3.9983674325048923,
        "mean_e2el_ms": 430.4103228729218,
        "median_e2el_ms": 67.83957104198635,
        "std_e2el_ms": 790.1198555776864,
        "p99_e2el_ms": 2526.691055088304,
        "run_number": 1
    },
    {
        "date": "20251201-113718",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 512,
        "duration": 2.7232323391363025,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6721068034803044,
        "request_goodput": null,
        "output_throughput": 399.1580095383091,
        "total_token_throughput": 901.8694309347628,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 40.96437369007617,
        "median_ttft_ms": 42.8772191517055,
        "std_ttft_ms": 6.396281570016992,
        "p99_ttft_ms": 44.81180233648047,
        "mean_tpot_ms": 3.612692692282843,
        "median_tpot_ms": 3.6691802088171244,
        "std_tpot_ms": 0.1993358336784239,
        "p99_tpot_ms": 3.780051796470119,
        "mean_itl_ms": 3.639933548326377,
        "median_itl_ms": 3.6176901776343584,
        "std_itl_ms": 0.563439560907363,
        "p99_itl_ms": 4.093126868829131,
        "mean_e2el_ms": 432.9849180066958,
        "median_e2el_ms": 67.46753549668938,
        "std_e2el_ms": 795.2569512207812,
        "p99_e2el_ms": 2542.111261680257,
        "run_number": 2
    },
    {
        "date": "20251201-113729",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 1024,
        "duration": 2.7218791691120714,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6739323749122152,
        "request_goodput": null,
        "output_throughput": 399.3564491529578,
        "total_token_throughput": 902.3177912784402,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 42.55014695227146,
        "median_ttft_ms": 43.69059298187494,
        "std_ttft_ms": 6.121116281694932,
        "p99_ttft_ms": 47.41172175388783,
        "mean_tpot_ms": 3.6358722464421867,
        "median_tpot_ms": 3.783444408327341,
        "std_tpot_ms": 0.2852965040456173,
        "p99_tpot_ms": 3.8291024573975134,
        "mean_itl_ms": 3.6415503861446594,
        "median_itl_ms": 3.6165202036499977,
        "std_itl_ms": 0.5809115473228016,
        "p99_itl_ms": 4.0935964323580265,
        "mean_e2el_ms": 434.74482954479754,
        "median_e2el_ms": 69.82628535479307,
        "std_e2el_ms": 794.2044230396625,
        "p99_e2el_ms": 2540.453344951384,
        "run_number": 0
    },
    {
        "date": "20251201-113739",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 1024,
        "duration": 2.7127290181815624,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.686324705850403,
        "request_goodput": null,
        "output_throughput": 400.70349552593876,
        "total_token_throughput": 905.3613477568589,
        "max_output_tokens_per_s": 612.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 34.14032207801938,
        "median_ttft_ms": 34.8338884068653,
        "std_ttft_ms": 7.9276247105256985,
        "p99_ttft_ms": 42.26792302215472,
        "mean_tpot_ms": 5.642540041270046,
        "median_tpot_ms": 3.78140639513731,
        "std_tpot_ms": 4.195769479156783,
        "p99_tpot_ms": 15.209791566245253,
        "mean_itl_ms": 3.658607052146226,
        "median_itl_ms": 3.600489813834429,
        "std_itl_ms": 0.7689881498547466,
        "p99_itl_ms": 4.186242381110787,
        "mean_e2el_ms": 428.1719795893878,
        "median_e2el_ms": 67.96926038805395,
        "std_e2el_ms": 792.8349815325716,
        "p99_e2el_ms": 2531.347984732129,
        "run_number": 1
    },
    {
        "date": "20251201-113750",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 1024,
        "duration": 2.7216297681443393,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6742690416772583,
        "request_goodput": null,
        "output_throughput": 399.393044830318,
        "total_token_throughput": 902.4004766359346,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.111735976301134,
        "median_ttft_ms": 42.81578306108713,
        "std_ttft_ms": 6.470259577804449,
        "p99_ttft_ms": 45.22923780605197,
        "mean_tpot_ms": 3.5924845692562872,
        "median_tpot_ms": 3.656610380858183,
        "std_tpot_ms": 0.2380460765682126,
        "p99_tpot_ms": 3.7796916788357837,
        "mean_itl_ms": 3.637410190125915,
        "median_itl_ms": 3.618770046159625,
        "std_itl_ms": 0.5503654081812254,
        "p99_itl_ms": 4.032983714714646,
        "mean_e2el_ms": 432.86052143666893,
        "median_e2el_ms": 67.83395551610738,
        "std_e2el_ms": 794.618481927279,
        "p99_e2el_ms": 2540.3301399759953,
        "run_number": 2
    },
    {
        "date": "20251201-113800",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 2048,
        "duration": 2.727579597849399,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.666254142641575,
        "request_goodput": null,
        "output_throughput": 398.5218253051392,
        "total_token_throughput": 900.4320174327709,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.074397531338036,
        "median_ttft_ms": 42.99644404090941,
        "std_ttft_ms": 6.417762204098238,
        "p99_ttft_ms": 45.261750172358006,
        "mean_tpot_ms": 3.794287551094038,
        "median_tpot_ms": 3.8147264359784976,
        "std_tpot_ms": 0.29698522701755475,
        "p99_tpot_ms": 4.127118856180459,
        "mean_itl_ms": 3.6597529758276384,
        "median_itl_ms": 3.6203700583428144,
        "std_itl_ms": 0.5701059592197759,
        "p99_itl_ms": 4.433720260858536,
        "mean_e2el_ms": 435.2294980082661,
        "median_e2el_ms": 70.0619105482474,
        "std_e2el_ms": 796.1887958744798,
        "p99_e2el_ms": 2546.2624908168805,
        "run_number": 0
    },
    {
        "date": "20251201-113811",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 2048,
        "duration": 2.7217755869496614,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.674072193147696,
        "request_goodput": null,
        "output_throughput": 399.3716473951546,
        "total_token_throughput": 902.3521306370742,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 44.01768380776048,
        "median_ttft_ms": 45.6363488920033,
        "std_ttft_ms": 6.806722522546994,
        "p99_ttft_ms": 48.48932030145079,
        "mean_tpot_ms": 3.9158158274423216,
        "median_tpot_ms": 3.836595867243078,
        "std_tpot_ms": 0.3229991899085759,
        "p99_tpot_ms": 4.6059146001935,
        "mean_itl_ms": 3.6429408650167336,
        "median_itl_ms": 3.6071708891540766,
        "std_itl_ms": 0.6281895617147676,
        "p99_itl_ms": 4.2867850977927455,
        "mean_e2el_ms": 436.3620469579473,
        "median_e2el_ms": 73.88424593955278,
        "std_e2el_ms": 793.3693935597064,
        "p99_e2el_ms": 2540.348234847188,
        "run_number": 1
    },
    {
        "date": "20251201-113821",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 2048,
        "duration": 2.7200426270719618,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6764129725292864,
        "request_goodput": null,
        "output_throughput": 399.6260901139334,
        "total_token_throughput": 902.9270260531928,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 42.381674400530756,
        "median_ttft_ms": 43.893848429434,
        "std_ttft_ms": 6.1666165692175605,
        "p99_ttft_ms": 47.190617034211755,
        "mean_tpot_ms": 3.581961472479748,
        "median_tpot_ms": 3.6679083947092295,
        "std_tpot_ms": 0.2372395667058908,
        "p99_tpot_ms": 3.763586420319317,
        "mean_itl_ms": 3.6318614975589925,
        "median_itl_ms": 3.6099099088460207,
        "std_itl_ms": 0.5596556966054278,
        "p99_itl_ms": 4.005902949720621,
        "mean_e2el_ms": 433.53283673059195,
        "median_e2el_ms": 68.47178051248193,
        "std_e2el_ms": 793.6457544529594,
        "p99_e2el_ms": 2538.362391355913,
        "run_number": 2
    },
    {
        "date": "20251201-113832",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 4096,
        "duration": 2.725218867883086,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6694300475645347,
        "request_goodput": null,
        "output_throughput": 398.8670461702649,
        "total_token_throughput": 901.2120196818497,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.07676313724369,
        "median_ttft_ms": 42.58942790329456,
        "std_ttft_ms": 6.2182195321722,
        "p99_ttft_ms": 45.77157779363915,
        "mean_tpot_ms": 3.7694852196075326,
        "median_tpot_ms": 3.8027471095761833,
        "std_tpot_ms": 0.17979253321619437,
        "p99_tpot_ms": 3.9905374804511666,
        "mean_itl_ms": 3.650792993729659,
        "median_itl_ms": 3.618469927459955,
        "std_itl_ms": 0.5803663916577348,
        "p99_itl_ms": 4.142439030110836,
        "mean_e2el_ms": 434.26684653386474,
        "median_e2el_ms": 69.40238550305367,
        "std_e2el_ms": 795.3875986990414,
        "p99_e2el_ms": 2543.295268930961,
        "run_number": 0
    },
    {
        "date": "20251201-113843",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 4096,
        "duration": 2.725306625943631,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.669311887625681,
        "request_goodput": null,
        "output_throughput": 398.8542021849115,
        "total_token_throughput": 901.1829996008672,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 42.13161894585937,
        "median_ttft_ms": 43.55984297581017,
        "std_ttft_ms": 5.724222744870086,
        "p99_ttft_ms": 46.5406433516182,
        "mean_tpot_ms": 4.025760575475871,
        "median_tpot_ms": 4.051560329066382,
        "std_tpot_ms": 0.36256250310628296,
        "p99_tpot_ms": 4.709762519225478,
        "mean_itl_ms": 3.6554887150167836,
        "median_itl_ms": 3.618811024352908,
        "std_itl_ms": 0.5142730993669968,
        "p99_itl_ms": 4.4354272820055485,
        "mean_e2el_ms": 435.8274825848639,
        "median_e2el_ms": 73.14030593261123,
        "std_e2el_ms": 795.1063018659815,
        "p99_e2el_ms": 2544.1425514430744,
        "run_number": 1
    },
    {
        "date": "20251201-113853",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 4096,
        "duration": 2.725760956062004,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6687002863403424,
        "request_goodput": null,
        "output_throughput": 398.7877211251952,
        "total_token_throughput": 901.0327903251881,
        "max_output_tokens_per_s": 609.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 42.369837034493685,
        "median_ttft_ms": 43.82213298231363,
        "std_ttft_ms": 5.834411453538207,
        "p99_ttft_ms": 46.98513286886737,
        "mean_tpot_ms": 3.9665182825399286,
        "median_tpot_ms": 3.9173924467629857,
        "std_tpot_ms": 0.37641950935474733,
        "p99_tpot_ms": 4.7729023140855125,
        "mean_itl_ms": 3.6518890929504355,
        "median_itl_ms": 3.617869922891259,
        "std_itl_ms": 0.49078732336730974,
        "p99_itl_ms": 4.45635280571878,
        "mean_e2el_ms": 435.6779392575845,
        "median_e2el_ms": 74.19391057919711,
        "std_e2el_ms": 795.1146266737894,
        "p99_e2el_ms": 2544.2598195280884,
        "run_number": 2
    },
    {
        "date": "20251201-113904",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 8192,
        "duration": 2.7150190758984536,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.683215373612357,
        "request_goodput": null,
        "output_throughput": 400.36551111166324,
        "total_token_throughput": 904.597695759195,
        "max_output_tokens_per_s": 611.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.45804946310818,
        "median_ttft_ms": 42.97159309498966,
        "std_ttft_ms": 6.426321080078575,
        "p99_ttft_ms": 45.435474494006485,
        "mean_tpot_ms": 3.6124297557282103,
        "median_tpot_ms": 3.638540394604206,
        "std_tpot_ms": 0.1896057690562084,
        "p99_tpot_ms": 3.7793497652264123,
        "mean_itl_ms": 3.63108227652054,
        "median_itl_ms": 3.6105799954384565,
        "std_itl_ms": 0.5716701409022669,
        "p99_itl_ms": 4.007292706519365,
        "mean_e2el_ms": 432.52530861645937,
        "median_e2el_ms": 68.23227053973824,
        "std_e2el_ms": 792.6035671167435,
        "p99_e2el_ms": 2534.385266983882,
        "run_number": 0
    },
    {
        "date": "20251201-113914",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 8192,
        "duration": 2.7249313660431653,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.669817201495559,
        "request_goodput": null,
        "output_throughput": 398.9091298025673,
        "total_token_throughput": 901.3071046873093,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.68763179332018,
        "median_ttft_ms": 43.20629395078868,
        "std_ttft_ms": 6.235380835070069,
        "p99_ttft_ms": 45.936325690709054,
        "mean_tpot_ms": 3.663146442625442,
        "median_tpot_ms": 3.7846123200974295,
        "std_tpot_ms": 0.24610229371221287,
        "p99_tpot_ms": 3.8572240630164742,
        "mean_itl_ms": 3.643689294040424,
        "median_itl_ms": 3.6176610738039017,
        "std_itl_ms": 0.5749682671213132,
        "p99_itl_ms": 4.0517198015004405,
        "mean_e2el_ms": 434.11267078481615,
        "median_e2el_ms": 69.19842096976936,
        "std_e2el_ms": 795.2419224873736,
        "p99_e2el_ms": 2543.1905017979448,
        "run_number": 1
    },
    {
        "date": "20251201-113925",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 8192,
        "duration": 2.7188327847979963,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.678048924492052,
        "request_goodput": null,
        "output_throughput": 399.80391809228604,
        "total_token_throughput": 903.3288158552479,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 42.65801776200533,
        "median_ttft_ms": 44.25950883887708,
        "std_ttft_ms": 6.214552030508995,
        "p99_ttft_ms": 46.80965796113014,
        "mean_tpot_ms": 3.573635533815098,
        "median_tpot_ms": 3.6243427716137675,
        "std_tpot_ms": 0.2377285973999846,
        "p99_tpot_ms": 3.7615767558801823,
        "mean_itl_ms": 3.630177999916681,
        "median_itl_ms": 3.608640981838107,
        "std_itl_ms": 0.5730482873325278,
        "p99_itl_ms": 4.076603204011917,
        "mean_e2el_ms": 433.6278514005244,
        "median_e2el_ms": 68.74883046839386,
        "std_e2el_ms": 793.3896900694361,
        "p99_e2el_ms": 2537.8274479834367,
        "run_number": 2
    },
    {
        "date": "20251201-113935",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 16384,
        "duration": 2.704517944017425,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.697516602587411,
        "request_goodput": null,
        "output_throughput": 401.92005470125156,
        "total_token_throughput": 908.1100775954682,
        "max_output_tokens_per_s": 611.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.929505742155015,
        "median_ttft_ms": 43.52743399795145,
        "std_ttft_ms": 6.406417861462699,
        "p99_ttft_ms": 46.07214248273522,
        "mean_tpot_ms": 3.5657305407592212,
        "median_tpot_ms": 3.6219489384307453,
        "std_tpot_ms": 0.24867506318725513,
        "p99_tpot_ms": 3.7696810121744537,
        "mean_itl_ms": 3.618343209652377,
        "median_itl_ms": 3.5916699562221766,
        "std_itl_ms": 0.5807211282838691,
        "p99_itl_ms": 3.97454178892076,
        "mean_e2el_ms": 431.62477544974536,
        "median_e2el_ms": 67.95777601655573,
        "std_e2el_ms": 789.5662164764263,
        "p99_e2el_ms": 2524.9943790026014,
        "run_number": 0
    },
    {
        "date": "20251201-113946",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 16384,
        "duration": 2.7209300741087645,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.675213889234357,
        "request_goodput": null,
        "output_throughput": 399.49574975977464,
        "total_token_throughput": 902.6325311959581,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.11453462392092,
        "median_ttft_ms": 42.8020985564217,
        "std_ttft_ms": 6.806319491684332,
        "p99_ttft_ms": 45.505066476762295,
        "mean_tpot_ms": 3.658113197716616,
        "median_tpot_ms": 3.8014449171346274,
        "std_tpot_ms": 0.26635521961897796,
        "p99_tpot_ms": 3.855802860007518,
        "mean_itl_ms": 3.643639078069765,
        "median_itl_ms": 3.617070149630308,
        "std_itl_ms": 0.5543054697891454,
        "p99_itl_ms": 4.086454715579748,
        "mean_e2el_ms": 433.5341662168503,
        "median_e2el_ms": 68.76960548106581,
        "std_e2el_ms": 794.2924215398551,
        "p99_e2el_ms": 2539.7755375830457,
        "run_number": 1
    },
    {
        "date": "20251201-113956",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 16384,
        "duration": 2.720634083962068,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6756137324564313,
        "request_goodput": null,
        "output_throughput": 399.5392127180141,
        "total_token_throughput": 902.7307326912995,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 40.45982381794602,
        "median_ttft_ms": 41.787273017689586,
        "std_ttft_ms": 5.549408799329373,
        "p99_ttft_ms": 44.58469299366698,
        "mean_tpot_ms": 4.003257058332474,
        "median_tpot_ms": 4.064080331267582,
        "std_tpot_ms": 0.33576402417167345,
        "p99_tpot_ms": 4.615000358782709,
        "mean_itl_ms": 3.649303639876616,
        "median_itl_ms": 3.611780935898423,
        "std_itl_ms": 0.5259347096336188,
        "p99_itl_ms": 4.475822001695633,
        "mean_e2el_ms": 433.4894708124921,
        "median_e2el_ms": 71.47351012099534,
        "std_e2el_ms": 794.0074246580601,
        "p99_e2el_ms": 2539.149357154966,
        "run_number": 2
    },
    {
        "date": "20251201-114007",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 32768,
        "duration": 2.720593463862315,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6756686115842574,
        "request_goodput": null,
        "output_throughput": 399.54517807920877,
        "total_token_throughput": 902.7442110050936,
        "max_output_tokens_per_s": 611.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.40648206230253,
        "median_ttft_ms": 42.94334852602333,
        "std_ttft_ms": 6.306963328582058,
        "p99_ttft_ms": 45.60627072583884,
        "mean_tpot_ms": 3.6863901730683835,
        "median_tpot_ms": 3.7833086974104915,
        "std_tpot_ms": 0.30319929859713257,
        "p99_tpot_ms": 3.9435460680785273,
        "mean_itl_ms": 3.6405858234826654,
        "median_itl_ms": 3.6120798904448748,
        "std_itl_ms": 0.5842323992175743,
        "p99_itl_ms": 4.303980870172382,
        "mean_e2el_ms": 433.4972952026874,
        "median_e2el_ms": 69.65083093382418,
        "std_e2el_ms": 793.9769415902894,
        "p99_e2el_ms": 2539.295788558666,
        "run_number": 0
    },
    {
        "date": "20251201-114017",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 32768,
        "duration": 2.7054972019977868,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6961782819866986,
        "request_goodput": null,
        "output_throughput": 401.77457925195415,
        "total_token_throughput": 907.7813860559332,
        "max_output_tokens_per_s": 612.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 39.42887932062149,
        "median_ttft_ms": 41.24300309922546,
        "std_ttft_ms": 6.053476463067457,
        "p99_ttft_ms": 43.74642145354301,
        "mean_tpot_ms": 3.6153966470432284,
        "median_tpot_ms": 3.7623701261027773,
        "std_tpot_ms": 0.2871067950107717,
        "p99_tpot_ms": 3.808952178961287,
        "mean_itl_ms": 3.6218162360553565,
        "median_itl_ms": 3.5904499236494303,
        "std_itl_ms": 0.5740816316313917,
        "p99_itl_ms": 4.176148418337108,
        "mean_e2el_ms": 429.49820533394814,
        "median_e2el_ms": 66.66964944452047,
        "std_e2el_ms": 790.398887634185,
        "p99_e2el_ms": 2525.4983447934505,
        "run_number": 1
    },
    {
        "date": "20251201-114028",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 32768,
        "duration": 2.715397762134671,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6827017166496603,
        "request_goodput": null,
        "output_throughput": 400.3096765998181,
        "total_token_throughput": 904.4715416091566,
        "max_output_tokens_per_s": 611.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 38.364231307059526,
        "median_ttft_ms": 40.011183940805495,
        "std_ttft_ms": 6.426850880178082,
        "p99_ttft_ms": 42.538215417880565,
        "mean_tpot_ms": 3.597071231054176,
        "median_tpot_ms": 3.6665499676018953,
        "std_tpot_ms": 0.21236883886728503,
        "p99_tpot_ms": 3.7684840615186577,
        "mean_itl_ms": 3.632901118810573,
        "median_itl_ms": 3.612780012190342,
        "std_itl_ms": 0.5603459061653877,
        "p99_itl_ms": 4.035910414531827,
        "mean_e2el_ms": 429.6274008927867,
        "median_e2el_ms": 64.94351499713957,
        "std_e2el_ms": 793.63958263525,
        "p99_e2el_ms": 2534.472971311771,
        "run_number": 2
    },
    {
        "date": "20251201-113935",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 16384,
        "duration": 2.704517944017425,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.697516602587411,
        "request_goodput": null,
        "output_throughput": 401.92005470125156,
        "total_token_throughput": 908.1100775954682,
        "max_output_tokens_per_s": 611.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.929505742155015,
        "median_ttft_ms": 43.52743399795145,
        "std_ttft_ms": 6.406417861462699,
        "p99_ttft_ms": 46.07214248273522,
        "mean_tpot_ms": 3.5657305407592212,
        "median_tpot_ms": 3.6219489384307453,
        "std_tpot_ms": 0.24867506318725513,
        "p99_tpot_ms": 3.7696810121744537,
        "mean_itl_ms": 3.618343209652377,
        "median_itl_ms": 3.5916699562221766,
        "std_itl_ms": 0.5807211282838691,
        "p99_itl_ms": 3.97454178892076,
        "mean_e2el_ms": 431.62477544974536,
        "median_e2el_ms": 67.95777601655573,
        "std_e2el_ms": 789.5662164764263,
        "p99_e2el_ms": 2524.9943790026014,
        "run_number": 0
    },
    {
        "date": "20251201-113946",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 16384,
        "duration": 2.7209300741087645,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.675213889234357,
        "request_goodput": null,
        "output_throughput": 399.49574975977464,
        "total_token_throughput": 902.6325311959581,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 41.11453462392092,
        "median_ttft_ms": 42.8020985564217,
        "std_ttft_ms": 6.806319491684332,
        "p99_ttft_ms": 45.505066476762295,
        "mean_tpot_ms": 3.658113197716616,
        "median_tpot_ms": 3.8014449171346274,
        "std_tpot_ms": 0.26635521961897796,
        "p99_tpot_ms": 3.855802860007518,
        "mean_itl_ms": 3.643639078069765,
        "median_itl_ms": 3.617070149630308,
        "std_itl_ms": 0.5543054697891454,
        "p99_itl_ms": 4.086454715579748,
        "mean_e2el_ms": 433.5341662168503,
        "median_e2el_ms": 68.76960548106581,
        "std_e2el_ms": 794.2924215398551,
        "p99_e2el_ms": 2539.7755375830457,
        "run_number": 1
    },
    {
        "date": "20251201-113956",
        "endpoint_type": "vllm",
        "backend": "vllm",
        "label": null,
        "model_id": "../../models/llama3-3b",
        "tokenizer_id": "../../models/llama3-3b",
        "num_prompts": 10,
        "request_rate": "inf",
        "burstiness": 1.0,
        "max_concurrency": 16384,
        "duration": 2.720634083962068,
        "completed": 10,
        "failed": 0,
        "total_input_tokens": 1369,
        "total_output_tokens": 1087,
        "request_throughput": 3.6756137324564313,
        "request_goodput": null,
        "output_throughput": 399.5392127180141,
        "total_token_throughput": 902.7307326912995,
        "max_output_tokens_per_s": 610.0,
        "max_concurrent_requests": 10,
        "mean_ttft_ms": 40.45982381794602,
        "median_ttft_ms": 41.787273017689586,
        "std_ttft_ms": 5.549408799329373,
        "p99_ttft_ms": 44.58469299366698,
        "mean_tpot_ms": 4.003257058332474,
        "median_tpot_ms": 4.064080331267582,
        "std_tpot_ms": 0.33576402417167345,
        "p99_tpot_ms": 4.615000358782709,
        "mean_itl_ms": 3.649303639876616,
        "median_itl_ms": 3.611780935898423,
        "std_itl_ms": 0.5259347096336188,
        "p99_itl_ms": 4.475822001695633,
        "mean_e2el_ms": 433.4894708124921,
        "median_e2el_ms": 71.47351012099534,
        "std_e2el_ms": 794.0074246580601,
        "p99_e2el_ms": 2539.149357154966,
        "run_number": 2
    }
]