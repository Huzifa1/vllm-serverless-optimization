{
    "date": "20251201-114007",
    "endpoint_type": "vllm",
    "backend": "vllm",
    "label": null,
    "model_id": "../../models/llama3-3b",
    "tokenizer_id": "../../models/llama3-3b",
    "num_prompts": 10,
    "request_rate": "inf",
    "burstiness": 1.0,
    "max_concurrency": 32768,
    "duration": 2.720593463862315,
    "completed": 10,
    "failed": 0,
    "total_input_tokens": 1369,
    "total_output_tokens": 1087,
    "request_throughput": 3.6756686115842574,
    "request_goodput": null,
    "output_throughput": 399.54517807920877,
    "total_token_throughput": 902.7442110050936,
    "max_output_tokens_per_s": 611.0,
    "max_concurrent_requests": 10,
    "mean_ttft_ms": 41.40648206230253,
    "median_ttft_ms": 42.94334852602333,
    "std_ttft_ms": 6.306963328582058,
    "p99_ttft_ms": 45.60627072583884,
    "mean_tpot_ms": 3.6863901730683835,
    "median_tpot_ms": 3.7833086974104915,
    "std_tpot_ms": 0.30319929859713257,
    "p99_tpot_ms": 3.9435460680785273,
    "mean_itl_ms": 3.6405858234826654,
    "median_itl_ms": 3.6120798904448748,
    "std_itl_ms": 0.5842323992175743,
    "p99_itl_ms": 4.303980870172382,
    "mean_e2el_ms": 433.4972952026874,
    "median_e2el_ms": 69.65083093382418,
    "std_e2el_ms": 793.9769415902894,
    "p99_e2el_ms": 2539.295788558666,
    "run_number": 0
}