Set parameter Username
Set parameter LicenseID to value 2752871
Academic license - for non-commercial use only - expires 2026-12-11
Set parameter OutputFlag to value 1
Set parameter TimeLimit to value 150
Gurobi Optimizer version 13.0.0 build v13.0.0rc1 (linux64 - "Debian GNU/Linux 12 (bookworm)")

CPU model: AMD EPYC 9354 32-Core Processor, instruction set [SSE2|AVX|AVX2|AVX512]
Thread count: 32 physical cores, 64 logical processors, using up to 32 threads

Non-default parameters:
TimeLimit  150

Optimize a model with 41393 rows, 10501 columns and 104864 nonzeros (Min)
Model fingerprint: 0xbe3415a1
Model has 1 linear objective coefficients
Variable types: 201 continuous, 10300 integer (10300 binary)
Coefficient statistics:
  Matrix range     [8e-02, 1e+03]
  Objective range  [1e+00, 1e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e+00, 3e+03]
Presolve removed 11103 rows and 1 columns
Presolve time: 0.18s
Presolved: 30290 rows, 10500 columns, 82660 nonzeros
Variable types: 199 continuous, 10301 integer (10300 binary)
Found heuristic solution: objective 64.7430743

Root relaxation: objective 4.663171e-01, 31494 iterations, 3.40 seconds (6.00 work units)

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.46632    0 8111   64.74307    0.46632  99.3%     -    5s
H    0     0                      64.6068994    0.46632  99.3%     -    5s
H    0     0                      63.5800506    0.73000  98.9%     -   14s
H    0     0                      61.8715605    0.73000  98.8%     -   14s
H    0     0                      61.7309822    0.73000  98.8%     -   14s
     0     0    0.82618    0 5151   61.73098    0.82618  98.7%     -   14s
     0     0    0.82618    0 5115   61.73098    0.82618  98.7%     -   15s
     0     0    1.91217    0 2228   61.73098    1.91217  96.9%     -   19s
H    0     0                      61.2359862    1.98585  96.8%     -   19s
H    0     0                      60.4579862    1.98585  96.7%     -   19s
H    0     0                      59.8499295    1.98585  96.7%     -   19s
H    0     0                      58.2878973    1.98585  96.6%     -   19s
H    0     0                      58.2858973    1.98585  96.6%     -   19s
H    0     0                      57.5098973    1.98585  96.5%     -   19s
H    0     0                      57.5078973    1.98585  96.5%     -   19s
H    0     0                      57.4570567    1.98585  96.5%     -   19s
H    0     0                      57.3818121    1.98585  96.5%     -   19s
H    0     0                      56.6038121    1.98585  96.5%     -   19s
H    0     0                      55.8235212    1.98585  96.4%     -   19s
H    0     0                      55.2346144    1.98585  96.4%     -   19s
H    0     0                      53.9311324    1.98585  96.3%     -   20s
H    0     0                      53.6073985    1.98585  96.3%     -   20s
H    0     0                      53.3443726    1.98585  96.3%     -   20s
H    0     0                      53.1995611    1.98585  96.3%     -   20s
     0     0    1.98585    0 2110   53.19956    1.98585  96.3%     -   20s
     0     0    1.98585    0 2059   53.19956    1.98585  96.3%     -   20s
     0     0    1.98585    0 2042   53.19956    1.98585  96.3%     -   20s
     0     0   43.63171    0  477   53.19956   43.63171  18.0%     -   22s
     0     0   43.63171    0  408   53.19956   43.63171  18.0%     -   23s
     0     0   43.63171    0  387   53.19956   43.63171  18.0%     -   23s
     0     0   43.63171    0  374   53.19956   43.63171  18.0%     -   23s
     0     0   43.63171    0    8   53.19956   43.63171  18.0%     -   23s
     0     0   43.63171    0   30   53.19956   43.63171  18.0%     -   24s
     0     0   43.63171    0    8   53.19956   43.63171  18.0%     -   24s
H    0     0                      53.0982280   43.63171  17.8%     -   26s
     0     0   43.63171    0   90   53.09823   43.63171  17.8%     -   26s
     0     0   43.63171    0    6   53.09823   43.63171  17.8%     -   26s
     0     0   43.63171    0    8   53.09823   43.63171  17.8%     -   27s
     0     0   43.63171    0   18   53.09823   43.63171  17.8%     -   27s
     0     0   43.63171    0   18   53.09823   43.63171  17.8%     -   27s
H    0     0                      52.9147352   43.63171  17.5%     -   27s
     0     0   43.63171    0   36   52.91474   43.63171  17.5%     -   27s
     0     0   43.63171    0   93   52.91474   43.63171  17.5%     -   28s
     0     0   43.63171    0    6   52.91474   43.63171  17.5%     -   28s
     0     0   43.63171    0    6   52.91474   43.63171  17.5%     -   28s
H    0     0                      52.1367352   43.63171  16.3%     -   29s
     0     2   43.63171    0    6   52.13674   43.63171  16.3%     -   29s
    15    32   43.63171    4  228   52.13674   43.63171  16.3%   608   30s
H 4009  3189                      52.1367352   43.63171  16.3%   246   36s
  4013  3191   45.53071   40   17   52.13674   43.63171  16.3%   246   40s
  4087  3274   43.63171   18  201   52.13674   43.63171  16.3%   260   45s
  4891  4754   43.63171   38  194   52.13674   43.63171  16.3%   261   52s
  5914  5988   43.63171   55  219   52.13674   43.63171  16.3%   264   57s
* 7099  5432              99      51.6997015   43.63171  15.6%   264   57s
  7640  6196   43.63171   74  260   51.69970   43.63171  15.6%   261   62s
H 7667  6032                      51.4629518   43.63171  15.2%   262   62s
H 7695  5852                      51.4592913   43.63171  15.2%   261   62s
  8723  7472   43.63171   88  214   51.45929   43.63171  15.2%   248   68s
H 8985  7247                      51.4592913   43.63171  15.2%   248   68s
H10030  6769                      51.4572913   43.63171  15.2%   238   68s
H10621  6443                      51.1290201   43.63171  14.7%   233   68s
 10894 12396   43.63171  103  303   51.12902   43.63171  14.7%   230   72s
 18430 12937 infeasible  188        51.12902   43.63171  14.7%   184   75s
H18433 12859                      50.9537813   43.63171  14.4%   184   75s
H22266 15637                      50.9537813   43.63171  14.4%   177   79s
 22623 16356 infeasible  213        50.95378   43.63171  14.4%   176   81s
 26903 18791   43.63171  216  128   50.95378   43.63171  14.4%   180   85s
 27685 18825   43.63171  218  296   50.95378   43.63171  14.4%   186   91s
 27805 19144 infeasible  218        50.95378   43.63171  14.4%   188   96s
H27841 19144                      50.9537811   43.63171  14.4%   188   96s
 29245 20452 infeasible  217        50.95378   43.63171  14.4%   189  102s
 33377 22655 infeasible  235        50.95378   43.63171  14.4%   190  107s
 34853 24440   43.63171  177  102   50.95378   43.63171  14.4%   193  110s
 42338 26221 infeasible  178        50.95378   43.63171  14.4%   195  115s
 43139 26247 infeasible  112        50.95378   43.63171  14.4%   196  120s
H43339 26573                      50.9517813   43.63171  14.4%   198  124s
H43453 26573                      50.9517813   43.63171  14.4%   198  124s
 43679 27087   43.63171  140  165   50.95178   43.63171  14.4%   199  126s
 44999 29123 infeasible  161        50.95178   43.63171  14.4%   204  130s
 47823 29405   43.63171  155   96   50.95178   43.63171  14.4%   208  136s
 49382 30494   43.63171  168   58   50.95178   43.63171  14.4%   211  141s
 51995 32840   43.63171  165   81   50.95178   43.63171  14.4%   212  145s
 56915 33883   43.63171   83   20   50.95178   43.63171  14.4%   208  150s

Cutting planes:
  Gomory: 31
  Cover: 2
  Implied bound: 317
  Projected implied bound: 138
  MIR: 678
  Mixing: 40
  Flow cover: 3207
  Inf proof: 13
  Zero half: 2
  RLT: 17
  Relax-and-lift: 144

Explored 58348 nodes (12310059 simplex iterations) in 150.05 seconds (343.29 work units)
Thread count was 32 (of 64 available processors)

Solution count 10: 50.9518 50.9518 50.9538 ... 51.463

Time limit reached
Best objective 5.095178134451e+01, best bound 4.363170571695e+01, gap 14.3667%

=== Optimal schedule ===
Models: ['llama3-3b', 'qwen-1.8b', 'qwen2.5-3b']
Makespan (C_max): 50.9518

Stage 0: model=qwen2.5-3b, start=1.0350, end=1.0350
  jobs: []
Stage 1: model=qwen2.5-3b, start=1.7677, end=1.7677
  jobs: []
Stage 2: model=qwen2.5-3b, start=1.7677, end=3.5163
  jobs: [0]
Stage 3: model=qwen2.5-3b, start=3.5163, end=3.5163
  jobs: []
Stage 4: model=qwen2.5-3b, start=3.5163, end=3.5163
  jobs: []
Stage 5: model=qwen2.5-3b, start=3.5163, end=3.5163
  jobs: []
Stage 6: model=llama3-3b, start=4.6353, end=4.9154
  jobs: []
Stage 7: model=qwen-1.8b, start=6.0064, end=6.0064
  jobs: []
Stage 8: model=qwen2.5-3b, start=7.0894, end=13.1474
  jobs: [3, 8, 11, 13, 21, 23, 26]
Stage 9: model=qwen2.5-3b, start=13.1474, end=13.1474
  jobs: []
Stage 10: model=qwen2.5-3b, start=13.9314, end=13.9314
  jobs: []
Stage 11: model=qwen2.5-3b, start=13.9314, end=15.0144
  jobs: []
Stage 12: model=qwen2.5-3b, start=15.0144, end=15.0144
  jobs: []
Stage 13: model=qwen2.5-3b, start=15.0144, end=18.2925
  jobs: [28, 51, 57]
Stage 14: model=llama3-3b, start=19.4115, end=19.4115
  jobs: []
Stage 15: model=llama3-3b, start=19.4115, end=19.4115
  jobs: []
Stage 16: model=llama3-3b, start=19.4115, end=19.9333
  jobs: []
Stage 17: model=llama3-3b, start=19.9333, end=25.1509
  jobs: [1, 2, 15, 17, 22, 24, 44, 56]
Stage 18: model=qwen-1.8b, start=25.9369, end=25.9369
  jobs: []
Stage 19: model=llama3-3b, start=27.0499, end=27.0499
  jobs: []
Stage 20: model=llama3-3b, start=27.0499, end=27.0499
  jobs: []
Stage 21: model=llama3-3b, start=27.0499, end=30.0000
  jobs: [5, 7, 9, 12, 16, 18, 30, 34, 35, 40, 43, 46, 50, 54, 63, 65, 66, 68, 70, 72, 76, 79]
Stage 22: model=llama3-3b, start=30.0000, end=30.0000
  jobs: []
Stage 23: model=llama3-3b, start=30.0000, end=32.2706
  jobs: [6, 19, 41, 71, 84]
Stage 24: model=qwen-1.8b, start=33.0566, end=43.6884
  jobs: [4, 14, 29, 31, 33, 37, 38, 39, 42, 45, 47, 48, 49, 52, 55, 58, 61, 69, 73, 74, 75, 77, 78, 81, 91, 92]
Stage 25: model=qwen-1.8b, start=43.6884, end=44.0869
  jobs: [98]
Stage 26: model=qwen-1.8b, start=44.0869, end=44.0869
  jobs: []
Stage 27: model=qwen2.5-3b, start=45.1699, end=48.1243
  jobs: [10, 20, 25, 27, 32, 36, 53, 59, 60, 62, 64, 67, 80, 82, 83, 85, 87, 88, 93, 94, 95, 97]
Stage 28: model=llama3-3b, start=49.2433, end=50.9518
  jobs: [86, 89, 90, 96, 99]

Job-level report (job_id, model, release, proc_time, sent_time, completion_time):
  0, qwen2.5-3b, r=0.0000, p=1.7486, sent=1.7677, done=3.5163
  1, llama3-3b, r=0.0000, p=4.7946, sent=19.9333, done=24.7278
  2, llama3-3b, r=0.0000, p=4.9308, sent=19.9333, done=24.8640
  3, qwen2.5-3b, r=0.0000, p=6.0580, sent=7.0894, done=13.1474
  4, qwen-1.8b, r=0.0000, p=4.7885, sent=33.0566, done=37.8451
  5, llama3-3b, r=0.0000, p=0.0831, sent=27.0499, done=27.1330
  6, llama3-3b, r=0.0000, p=2.0592, sent=30.0000, done=32.0592
  7, llama3-3b, r=0.0000, p=1.3748, sent=27.0499, done=28.4247
  8, qwen2.5-3b, r=0.0000, p=3.0462, sent=7.0894, done=10.1356
  9, llama3-3b, r=0.0000, p=1.2439, sent=27.0499, done=28.2939
  10, qwen2.5-3b, r=3.0000, p=0.9051, sent=45.1699, done=46.0750
  11, qwen2.5-3b, r=3.0000, p=2.6551, sent=7.0894, done=9.7445
  12, llama3-3b, r=3.0000, p=0.6538, sent=27.0499, done=27.7037
  13, qwen2.5-3b, r=3.0000, p=5.6331, sent=7.0894, done=12.7225
  14, qwen-1.8b, r=3.0000, p=5.2656, sent=33.0566, done=38.3222
  15, llama3-3b, r=3.0000, p=4.7641, sent=19.9333, done=24.6974
  16, llama3-3b, r=3.0000, p=0.5851, sent=27.0499, done=27.6350
  17, llama3-3b, r=3.0000, p=3.5390, sent=19.9333, done=23.4722
  18, llama3-3b, r=3.0000, p=0.5217, sent=27.0499, done=27.5717
  19, llama3-3b, r=3.0000, p=1.8882, sent=30.0000, done=31.8882
  20, qwen2.5-3b, r=3.0000, p=1.2497, sent=45.1699, done=46.4196
  21, qwen2.5-3b, r=3.0000, p=1.6782, sent=7.0894, done=8.7676
  22, llama3-3b, r=3.0000, p=2.7119, sent=19.9333, done=22.6451
  23, qwen2.5-3b, r=3.0000, p=2.7339, sent=7.0894, done=9.8233
  24, llama3-3b, r=3.0000, p=5.2177, sent=19.9333, done=25.1509
  25, qwen2.5-3b, r=6.0000, p=0.3619, sent=45.1699, done=45.5318
  26, qwen2.5-3b, r=6.0000, p=3.0281, sent=7.0894, done=10.1175
  27, qwen2.5-3b, r=6.0000, p=0.3083, sent=45.1699, done=45.4782
  28, qwen2.5-3b, r=9.0000, p=1.7523, sent=15.0144, done=16.7667
  29, qwen-1.8b, r=9.0000, p=1.4426, sent=33.0566, done=34.4993
  30, llama3-3b, r=9.0000, p=2.4459, sent=27.0499, done=29.4958
  31, qwen-1.8b, r=9.0000, p=2.2511, sent=33.0566, done=35.3078
  32, qwen2.5-3b, r=9.0000, p=0.7998, sent=45.1699, done=45.9697
  33, qwen-1.8b, r=9.0000, p=0.1591, sent=33.0566, done=33.2157
  34, llama3-3b, r=9.0000, p=0.2102, sent=27.0499, done=27.2601
  35, llama3-3b, r=9.0000, p=1.0818, sent=27.0499, done=28.1317
  36, qwen2.5-3b, r=9.0000, p=1.3713, sent=45.1699, done=46.5412
  37, qwen-1.8b, r=12.0000, p=1.2080, sent=33.0566, done=34.2647
  38, qwen-1.8b, r=12.0000, p=1.4035, sent=33.0566, done=34.4601
  39, qwen-1.8b, r=12.0000, p=2.0120, sent=33.0566, done=35.0687
  40, llama3-3b, r=12.0000, p=1.5795, sent=27.0499, done=28.6294
  41, llama3-3b, r=12.0000, p=2.1189, sent=30.0000, done=32.1189
  42, qwen-1.8b, r=12.0000, p=1.7504, sent=33.0566, done=34.8071
  43, llama3-3b, r=12.0000, p=2.4983, sent=27.0499, done=29.5482
  44, llama3-3b, r=12.0000, p=2.3420, sent=19.9333, done=22.2753
  45, qwen-1.8b, r=15.0000, p=1.9413, sent=33.0566, done=34.9979
  46, llama3-3b, r=15.0000, p=0.6323, sent=27.0499, done=27.6822
  47, qwen-1.8b, r=15.0000, p=1.7415, sent=33.0566, done=34.7981
  48, qwen-1.8b, r=15.0000, p=1.5574, sent=33.0566, done=34.6140
  49, qwen-1.8b, r=15.0000, p=1.5429, sent=33.0566, done=34.5995
  50, llama3-3b, r=15.0000, p=1.0507, sent=27.0499, done=28.1006
  51, qwen2.5-3b, r=15.0000, p=1.4124, sent=15.0144, done=16.4268
  52, qwen-1.8b, r=15.0000, p=1.7933, sent=33.0566, done=34.8499
  53, qwen2.5-3b, r=15.0000, p=1.3009, sent=45.1699, done=46.4708
  54, llama3-3b, r=15.0000, p=0.2028, sent=27.0499, done=27.2527
  55, qwen-1.8b, r=15.0000, p=1.3941, sent=33.0566, done=34.4508
  56, llama3-3b, r=15.0000, p=3.8021, sent=19.9333, done=23.7354
  57, qwen2.5-3b, r=15.0000, p=3.2781, sent=15.0144, done=18.2925
  58, qwen-1.8b, r=15.0000, p=1.1906, sent=33.0566, done=34.2473
  59, qwen2.5-3b, r=18.0000, p=1.9018, sent=45.1699, done=47.0717
  60, qwen2.5-3b, r=18.0000, p=2.5191, sent=45.1699, done=47.6890
  61, qwen-1.8b, r=18.0000, p=0.1443, sent=33.0566, done=33.2009
  62, qwen2.5-3b, r=18.0000, p=1.1891, sent=45.1699, done=46.3590
  63, llama3-3b, r=21.0000, p=0.9104, sent=27.0499, done=27.9603
  64, qwen2.5-3b, r=21.0000, p=2.1833, sent=45.1699, done=47.3532
  65, llama3-3b, r=21.0000, p=1.8291, sent=27.0499, done=28.8790
  66, llama3-3b, r=21.0000, p=1.6249, sent=27.0499, done=28.6748
  67, qwen2.5-3b, r=21.0000, p=1.4010, sent=45.1699, done=46.5709
  68, llama3-3b, r=21.0000, p=1.6077, sent=27.0499, done=28.6576
  69, qwen-1.8b, r=24.0000, p=4.2591, sent=33.0566, done=37.3157
  70, llama3-3b, r=24.0000, p=0.8515, sent=27.0499, done=27.9014
  71, llama3-3b, r=24.0000, p=2.0015, sent=30.0000, done=32.0015
  72, llama3-3b, r=24.0000, p=0.8031, sent=27.0499, done=27.8530
  73, qwen-1.8b, r=27.0000, p=0.1547, sent=33.0566, done=33.2113
  74, qwen-1.8b, r=27.0000, p=2.1250, sent=33.0566, done=35.1816
  75, qwen-1.8b, r=27.0000, p=2.5188, sent=33.0566, done=35.5754
  76, llama3-3b, r=27.0000, p=2.9501, sent=27.0499, done=30.0000
  77, qwen-1.8b, r=27.0000, p=0.7031, sent=33.0566, done=33.7598
  78, qwen-1.8b, r=27.0000, p=0.1432, sent=33.0566, done=33.1999
  79, llama3-3b, r=27.0000, p=1.4266, sent=27.0499, done=28.4765
  80, qwen2.5-3b, r=27.0000, p=1.8684, sent=45.1699, done=47.0383
  81, qwen-1.8b, r=27.0000, p=1.8846, sent=33.0566, done=34.9412
  82, qwen2.5-3b, r=27.0000, p=1.5676, sent=45.1699, done=46.7375
  83, qwen2.5-3b, r=30.0000, p=0.3644, sent=45.1699, done=45.5343
  84, llama3-3b, r=30.0000, p=2.2706, sent=30.0000, done=32.2706
  85, qwen2.5-3b, r=30.0000, p=2.1209, sent=45.1699, done=47.2908
  86, llama3-3b, r=33.0000, p=1.2058, sent=49.2433, done=50.4491
  87, qwen2.5-3b, r=33.0000, p=2.6280, sent=45.1699, done=47.7980
  88, qwen2.5-3b, r=33.0000, p=2.9544, sent=45.1699, done=48.1243
  89, llama3-3b, r=33.0000, p=0.5542, sent=49.2433, done=49.7975
  90, llama3-3b, r=33.0000, p=0.6146, sent=49.2433, done=49.8579
  91, qwen-1.8b, r=33.0000, p=9.8052, sent=33.0566, done=42.8619
  92, qwen-1.8b, r=33.0000, p=10.6317, sent=33.0566, done=43.6884
  93, qwen2.5-3b, r=36.0000, p=2.4672, sent=45.1699, done=47.6372
  94, qwen2.5-3b, r=36.0000, p=2.5370, sent=45.1699, done=47.7069
  95, qwen2.5-3b, r=36.0000, p=2.2389, sent=45.1699, done=47.4088
  96, llama3-3b, r=36.0000, p=1.1653, sent=49.2433, done=50.4086
  97, qwen2.5-3b, r=36.0000, p=1.8329, sent=45.1699, done=47.0028
  98, qwen-1.8b, r=36.0000, p=0.3986, sent=43.6884, done=44.0869
  99, llama3-3b, r=36.0000, p=1.7085, sent=49.2433, done=50.9518

Wrote schedule to schedule_output.json
