DEBUG 11-20 15:29:59.844 [__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 11-20 15:29:59.844 [__init__.py:34] Checking if TPU platform is available.
DEBUG 11-20 15:29:59.844 [__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 11-20 15:29:59.844 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:29:59.855 [__init__.py:78] Confirmed CUDA platform is available.
DEBUG 11-20 15:29:59.862 [__init__.py:106] Checking if ROCm platform is available.
DEBUG 11-20 15:29:59.862 [__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 11-20 15:29:59.862 [__init__.py:127] Checking if XPU platform is available.
DEBUG 11-20 15:29:59.863 [__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 11-20 15:29:59.863 [__init__.py:153] Checking if CPU platform is available.
DEBUG 11-20 15:29:59.863 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:29:59.866 [__init__.py:78] Confirmed CUDA platform is available.
INFO 11-20 15:29:59.873 [__init__.py:216] Automatically detected platform cuda.
WARNING 11-20 15:30:01.187 [api_server.py:966] SECURITY WARNING: Development endpoints are enabled! This should NOT be used in production!
DEBUG 11-20 15:30:01.190 [utils.py:163] Setting VLLM_WORKER_MULTIPROC_METHOD to 'spawn'
DEBUG 11-20 15:30:01.194 [__init__.py:36] Available plugins for group vllm.general_plugins:
DEBUG 11-20 15:30:01.194 [__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 11-20 15:30:01.194 [__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:01.279 [api_server.py:1839] vLLM API server version 0.11.0
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:01.281 [utils.py:233] non-default args: {'port': 8501, 'model': '../models/qwen2.5-3b'}
[1;36m(APIServer pid=797276)[0;0m DEBUG 11-20 15:30:01.284 [registry.py:498] Loaded model info for class vllm.model_executor.models.qwen2.Qwen2ForCausalLM from cache
[1;36m(APIServer pid=797276)[0;0m DEBUG 11-20 15:30:01.284 [log_time.py:27] Registry inspect model class: Elapsed time 0.0002718 secs
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:01.285 [model.py:547] Resolved architecture: Qwen2ForCausalLM
[1;36m(APIServer pid=797276)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:01.296 [model.py:1510] Using max model len 32768
[1;36m(APIServer pid=797276)[0;0m DEBUG 11-20 15:30:01.318 [arg_utils.py:1672] Setting max_num_batched_tokens to 8192 for OPENAI_API_SERVER usage context.
[1;36m(APIServer pid=797276)[0;0m DEBUG 11-20 15:30:01.318 [arg_utils.py:1681] Setting max_num_seqs to 1024 for OPENAI_API_SERVER usage context.
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:01.398 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.
DEBUG 11-20 15:30:03.674 [__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 11-20 15:30:03.674 [__init__.py:34] Checking if TPU platform is available.
DEBUG 11-20 15:30:03.674 [__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 11-20 15:30:03.674 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:30:03.684 [__init__.py:78] Confirmed CUDA platform is available.
DEBUG 11-20 15:30:03.693 [__init__.py:106] Checking if ROCm platform is available.
DEBUG 11-20 15:30:03.693 [__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 11-20 15:30:03.693 [__init__.py:127] Checking if XPU platform is available.
DEBUG 11-20 15:30:03.693 [__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 11-20 15:30:03.693 [__init__.py:153] Checking if CPU platform is available.
DEBUG 11-20 15:30:03.694 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:30:03.696 [__init__.py:78] Confirmed CUDA platform is available.
INFO 11-20 15:30:03.704 [__init__.py:216] Automatically detected platform cuda.
WARNING 11-20 15:30:05.040 [api_server.py:966] SECURITY WARNING: Development endpoints are enabled! This should NOT be used in production!
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:05.144 [core.py:644] Waiting for init message from front-end.
[1;36m(APIServer pid=797276)[0;0m DEBUG 11-20 15:30:05.145 [utils.py:859] HELLO from local core engine process 0.
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:05.145 [core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/53b22a69-f823-4ca9-8937-a8614c19c6cc'], outputs=['ipc:///tmp/b459d0df-7d19-4967-a0c6-c2fe0017e822'], coordinator_input=None, coordinator_output=None, frontend_stats_publish_address=None), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 0, '_data_parallel_master_port_list': [], 'data_parallel_size': 1})
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:05.145 [core.py:487] Has DP Coordinator: False, stats publish address: None
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:05.148 [__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:05.148 [__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:05.148 [__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:05.149 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='../models/qwen2.5-3b', speculative_config=None, tokenizer='../models/qwen2.5-3b', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=../models/qwen2.5-3b, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:06.252 [decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:06.467 [decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:06.467 [decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:06.570 [__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f6f882af4d0>
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:06.700 [parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://131.234.187.203:60273 backend=nccl
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:06.726 [parallel_state.py:1083] Detected 1 nodes in the distributed environment
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:06.730 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=797629)[0;0m WARNING 11-20 15:30:06.930 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:06.936 [__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:06.967 [gpu_model_runner.py:2602] Starting to load model ../models/qwen2.5-3b...
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:07.169 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:07.223 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:07.272 [backends.py:42] Using InductorAdaptor
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:07.288 [compilation.py:649] enabled custom ops: Counter()
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:07.288 [compilation.py:650] disabled custom ops: Counter({'rms_norm': 73, 'column_parallel_linear': 72, 'row_parallel_linear': 72, 'silu_and_mul': 36, 'vocab_parallel_embedding': 1, 'rotary_embedding': 1, 'logits_processor': 1})
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:07.288 [base_loader.py:48] Loading weights on cuda ...
[1;36m(EngineCore_DP0 pid=797629)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=797629)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  4.24it/s]
[1;36m(EngineCore_DP0 pid=797629)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.65it/s]
[1;36m(EngineCore_DP0 pid=797629)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.80it/s]
[1;36m(EngineCore_DP0 pid=797629)[0;0m 
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:08.119 [default_loader.py:267] Loading weights took 0.83 seconds
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:08.514 [gpu_model_runner.py:2653] Model loading took 5.7916 GiB and 0.953797 seconds
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:08.708 [decorators.py:256] Start compiling function <code object forward at 0x14188ad0, file "/local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 341>
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] Traced files (to be considered for compilation cache):
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/torch/_dynamo/polyfills/__init__.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/torch/nn/modules/container.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/attention/layer.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/distributed/communication_op.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/distributed/parallel_state.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/custom_op.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/activation.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/layernorm.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/linear.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/rotary_embedding/base.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/rotary_embedding/common.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/utils.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.036 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/platforms/interface.py
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:12.348 [backends.py:548] Using cache directory: /local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:12.349 [backends.py:559] Dynamo bytecode transform time: 3.64 s
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.848 [backends.py:127] Directly load the 0-th graph for dynamic shape from inductor via handle ('f4zn7nys6zuglogyh3ak3d6jl4mqbzcobphiyhuiotqjfshtmbyg', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/k2/ck2pa66pf4qdtnmvzqs32b2pnkx3rjdofjtdveh6mgg62qchvkka.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.882 [backends.py:127] Directly load the 1-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.914 [backends.py:127] Directly load the 2-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.946 [backends.py:127] Directly load the 3-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:12.978 [backends.py:127] Directly load the 4-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.009 [backends.py:127] Directly load the 5-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.041 [backends.py:127] Directly load the 6-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.072 [backends.py:127] Directly load the 7-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.104 [backends.py:127] Directly load the 8-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.135 [backends.py:127] Directly load the 9-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.167 [backends.py:127] Directly load the 10-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.199 [backends.py:127] Directly load the 11-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.230 [backends.py:127] Directly load the 12-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.262 [backends.py:127] Directly load the 13-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.293 [backends.py:127] Directly load the 14-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.325 [backends.py:127] Directly load the 15-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.356 [backends.py:127] Directly load the 16-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.388 [backends.py:127] Directly load the 17-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.419 [backends.py:127] Directly load the 18-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.451 [backends.py:127] Directly load the 19-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.482 [backends.py:127] Directly load the 20-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.514 [backends.py:127] Directly load the 21-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.545 [backends.py:127] Directly load the 22-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.577 [backends.py:127] Directly load the 23-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.608 [backends.py:127] Directly load the 24-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.640 [backends.py:127] Directly load the 25-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.671 [backends.py:127] Directly load the 26-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.702 [backends.py:127] Directly load the 27-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.734 [backends.py:127] Directly load the 28-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.766 [backends.py:127] Directly load the 29-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.797 [backends.py:127] Directly load the 30-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.829 [backends.py:127] Directly load the 31-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.861 [backends.py:127] Directly load the 32-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.893 [backends.py:127] Directly load the 33-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.924 [backends.py:127] Directly load the 34-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.956 [backends.py:127] Directly load the 35-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:13.967 [backends.py:127] Directly load the 36-th graph for dynamic shape from inductor via handle ('ffikq2ptajgvmx4re6ssmyj2aacncir5qasy2imeswvalxonvcl7', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/th/cthyymxxwpvo2rut5ph6ohvl4xoaowjozgxuwzokakzkk5rbytt4.py')
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:13.967 [backends.py:164] Directly load the compiled graph(s) for dynamic shape from the cache, took 1.141 s
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:14.448 [monitor.py:34] torch.compile takes 3.64 s in total
[1;36m(APIServer pid=797276)[0;0m DEBUG 11-20 15:30:15.155 [utils.py:776] Waiting for 1 local, 0 remote core engine proc(s) to start.
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.171 [gpu_worker.py:284] Initial free memory: 92.48 GiB; Requested memory: 0.90 (util), 83.78 GiB
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.172 [gpu_worker.py:291] Free memory after profiling: 86.39 GiB (total), 77.69 GiB (within requested)
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.172 [gpu_worker.py:297] Memory profiling takes 6.46 seconds. Total non KV cache memory: 11.51GiB; torch peak memory increase: 5.58GiB; non-torch forward increase memory: 0.13GiB; weights memory: 5.79GiB.
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:15.172 [gpu_worker.py:298] Available KV cache memory: 72.27 GiB
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:15.423 [kv_cache_utils.py:1087] GPU KV cache size: 2,105,040 tokens
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:15.423 [kv_cache_utils.py:1091] Maximum concurrency for 32,768 tokens per request: 64.24x
[1;36m(EngineCore_DP0 pid=797629)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.713 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=512, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.753 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=504, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.789 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=496, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 3/67 [00:00<00:02, 23.97it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.824 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=488, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.866 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=480, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.903 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=472, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 6/67 [00:00<00:02, 25.34it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.940 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=464, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:15.980 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=456, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.020 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=448, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–Ž        | 9/67 [00:00<00:02, 25.49it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.057 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=440, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.096 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=432, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.133 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=424, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 12/67 [00:00<00:02, 25.83it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.171 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=416, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.210 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=408, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.248 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=400, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:00<00:02, 25.90it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.284 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=392, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.326 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=384, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.364 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=376, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:00<00:01, 25.89it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.400 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=368, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.442 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=360, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.480 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=352, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:00<00:01, 25.85it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.518 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=344, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.560 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=336, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.599 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=328, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:00<00:01, 25.66it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.640 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=320, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.680 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=312, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.717 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=304, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:01<00:01, 25.49it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.757 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=296, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.800 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=288, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.839 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=280, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:01<00:01, 25.20it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.879 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=272, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.924 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=264, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:16.966 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=256, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:01<00:01, 24.72it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.007 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=248, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.051 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=240, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.090 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=232, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:01<00:01, 24.53it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.134 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=224, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.177 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=216, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.221 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=208, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:01<00:01, 24.04it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.261 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=200, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.307 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=192, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.347 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=184, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:01<00:01, 23.87it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.391 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=176, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.436 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=168, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.481 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=160, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:01<00:00, 23.42it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.523 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=152, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.569 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=144, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.610 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=136, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:01<00:00, 23.32it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.659 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=128, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.706 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=120, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.753 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=112, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:02<00:00, 22.59it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.799 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=104, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.848 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=96, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.893 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=88, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:02<00:00, 22.23it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.942 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=80, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:17.989 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=72, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.034 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=64, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:02<00:00, 21.87it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.077 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=56, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.124 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=48, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.167 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=40, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:02<00:00, 22.11it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.212 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=32, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.257 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=24, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.302 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=16, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:02<00:00, 22.13it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.342 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=8, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.380 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=4, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.418 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=2, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:02<00:00, 23.13it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.463 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=1, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:02<00:00, 23.87it/s]
[1;36m(EngineCore_DP0 pid=797629)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.515 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=512, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.542 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=504, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.568 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=496, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.594 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=488, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):   6%|â–Œ         | 4/67 [00:00<00:01, 35.55it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.619 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=480, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.644 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=472, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.669 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=464, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.695 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=456, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  12%|â–ˆâ–        | 8/67 [00:00<00:01, 37.74it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.721 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=448, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.746 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=440, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.771 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=432, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.796 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=424, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  18%|â–ˆâ–Š        | 12/67 [00:00<00:01, 38.58it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.821 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=416, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.846 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=408, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.871 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=400, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.897 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=392, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  24%|â–ˆâ–ˆâ–       | 16/67 [00:00<00:01, 38.94it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.923 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=384, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.948 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=376, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.972 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=368, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:18.998 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=360, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:01, 39.31it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.023 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=352, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.048 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=344, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.074 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=336, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.099 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=328, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:00<00:01, 39.35it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.124 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=320, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.150 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=312, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.175 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=304, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.200 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=296, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/67 [00:00<00:00, 39.45it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.225 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=288, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.250 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=280, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.276 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=272, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.301 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=264, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:00<00:00, 39.36it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.327 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=256, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.353 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=248, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.378 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=240, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.404 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=232, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:00<00:00, 39.32it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.429 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=224, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.456 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=216, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.482 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=208, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.507 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=200, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:01<00:00, 39.12it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.533 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=192, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.558 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=184, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.584 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=176, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.609 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=168, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:01<00:00, 39.19it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.634 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=160, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.661 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=152, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.686 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=144, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.711 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=136, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:01<00:00, 39.20it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.736 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=128, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.761 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=120, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.786 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=112, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.812 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=104, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:01<00:00, 39.24it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.838 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=96, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.863 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=88, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.888 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=80, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.912 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=72, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.938 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=64, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:01<00:00, 39.53it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.963 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=56, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:19.988 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=48, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:20.013 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=40, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:20.039 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=32, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:01<00:00, 39.48it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:20.064 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=24, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:20.089 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=16, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:20.114 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=8, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:20.138 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=4, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:20.163 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=2, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:01<00:00, 39.84it/s][1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:20.187 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=1, uniform_decode=True))
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 39.25it/s]
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:20.473 [gpu_model_runner.py:3480] Graph capturing finished in 5 secs, took 0.69 GiB
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:20.473 [gpu_worker.py:393] Free memory on device (92.48/93.09 GiB) on startup. Desired GPU memory utilization is (0.9, 83.78 GiB). Actual usage is 5.79 GiB for weight, 5.58 GiB for peak activation, 0.13 GiB for non-torch memory, and 0.69 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=76700961075` (71.43 GiB) to fit into requested memory, or `--kv-cache-memory=86047069696` (80.14 GiB) to fully utilize gpu memory. Current kv cache memory in use is 72.27 GiB.
[1;36m(EngineCore_DP0 pid=797629)[0;0m INFO 11-20 15:30:20.495 [core.py:210] init engine (profile, create kv cache, warmup model) took 11.98 seconds
[1;36m(APIServer pid=797276)[0;0m DEBUG 11-20 15:30:20.785 [utils.py:859] READY from local core engine process 0.
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:20.971 [loggers.py:147] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 131565
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:21.067 [core.py:737] EngineCore waiting for work.
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:21.068 [core.py:737] EngineCore waiting for work.
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:21.108 [core.py:737] EngineCore waiting for work.
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.109 [api_server.py:1634] Supported_tasks: ['generate']
[1;36m(APIServer pid=797276)[0;0m WARNING 11-20 15:30:21.110 [model.py:1389] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.111 [serving_responses.py:137] Using default chat sampling params from model: {'max_tokens': 2048}
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.112 [serving_chat.py:139] Using default chat sampling params from model: {'max_tokens': 2048}
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.113 [serving_completion.py:76] Using default completion sampling params from model: {'max_tokens': 2048}
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.113 [api_server.py:1912] Starting vLLM API server 0 on http://0.0.0.0:8501
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.114 [launcher.py:34] Available routes are:
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.114 [launcher.py:42] Route: /openapi.json, Methods: HEAD, GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.114 [launcher.py:42] Route: /docs, Methods: HEAD, GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.114 [launcher.py:42] Route: /docs/oauth2-redirect, Methods: HEAD, GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.114 [launcher.py:42] Route: /redoc, Methods: HEAD, GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.115 [launcher.py:42] Route: /health, Methods: GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.115 [launcher.py:42] Route: /load, Methods: GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.115 [launcher.py:42] Route: /ping, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.115 [launcher.py:42] Route: /ping, Methods: GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.116 [launcher.py:42] Route: /tokenize, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.116 [launcher.py:42] Route: /detokenize, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.116 [launcher.py:42] Route: /v1/models, Methods: GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.116 [launcher.py:42] Route: /version, Methods: GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.116 [launcher.py:42] Route: /v1/responses, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.117 [launcher.py:42] Route: /v1/responses/{response_id}, Methods: GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.117 [launcher.py:42] Route: /v1/responses/{response_id}/cancel, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.117 [launcher.py:42] Route: /v1/chat/completions, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.117 [launcher.py:42] Route: /v1/completions, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.117 [launcher.py:42] Route: /v1/embeddings, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.118 [launcher.py:42] Route: /pooling, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.118 [launcher.py:42] Route: /classify, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.118 [launcher.py:42] Route: /score, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.118 [launcher.py:42] Route: /v1/score, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.118 [launcher.py:42] Route: /v1/audio/transcriptions, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.119 [launcher.py:42] Route: /v1/audio/translations, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.119 [launcher.py:42] Route: /rerank, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.119 [launcher.py:42] Route: /v1/rerank, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.119 [launcher.py:42] Route: /v2/rerank, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.119 [launcher.py:42] Route: /server_info, Methods: GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.120 [launcher.py:42] Route: /reset_prefix_cache, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.120 [launcher.py:42] Route: /sleep, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.120 [launcher.py:42] Route: /wake_up, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.120 [launcher.py:42] Route: /is_sleeping, Methods: GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.120 [launcher.py:42] Route: /collective_rpc, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.121 [launcher.py:42] Route: /scale_elastic_ep, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.121 [launcher.py:42] Route: /is_scaling_elastic_ep, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.121 [launcher.py:42] Route: /invocations, Methods: POST
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.121 [launcher.py:42] Route: /metrics, Methods: GET
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.899 [api_server.py:1024] check whether the engine is sleeping
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:21.900 [core.py:737] EngineCore waiting for work.
[1;36m(APIServer pid=797276)[0;0m INFO 11-20 15:30:21.970 [api_server.py:1024] check whether the engine is sleeping
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:21.972 [core.py:737] EngineCore waiting for work.
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:21.984 [core.py:743] EngineCore loop active.
[1;36m(EngineCore_DP0 pid=797629)[0;0m DEBUG 11-20 15:30:22.963 [core.py:737] EngineCore waiting for work.
DEBUG 11-20 15:30:47.092 [__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 11-20 15:30:47.092 [__init__.py:34] Checking if TPU platform is available.
DEBUG 11-20 15:30:47.092 [__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 11-20 15:30:47.092 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:30:47.103 [__init__.py:78] Confirmed CUDA platform is available.
DEBUG 11-20 15:30:47.110 [__init__.py:106] Checking if ROCm platform is available.
DEBUG 11-20 15:30:47.111 [__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 11-20 15:30:47.111 [__init__.py:127] Checking if XPU platform is available.
DEBUG 11-20 15:30:47.111 [__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 11-20 15:30:47.111 [__init__.py:153] Checking if CPU platform is available.
DEBUG 11-20 15:30:47.111 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:30:47.114 [__init__.py:78] Confirmed CUDA platform is available.
INFO 11-20 15:30:47.121 [__init__.py:216] Automatically detected platform cuda.
WARNING 11-20 15:30:48.439 [api_server.py:966] SECURITY WARNING: Development endpoints are enabled! This should NOT be used in production!
DEBUG 11-20 15:30:48.442 [utils.py:163] Setting VLLM_WORKER_MULTIPROC_METHOD to 'spawn'
DEBUG 11-20 15:30:48.446 [__init__.py:36] Available plugins for group vllm.general_plugins:
DEBUG 11-20 15:30:48.446 [__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 11-20 15:30:48.446 [__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:30:48.531 [api_server.py:1839] vLLM API server version 0.11.0
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:30:48.533 [utils.py:233] non-default args: {'port': 8501, 'model': '../models/qwen2.5-3b'}
[1;36m(APIServer pid=798917)[0;0m DEBUG 11-20 15:30:48.537 [registry.py:498] Loaded model info for class vllm.model_executor.models.qwen2.Qwen2ForCausalLM from cache
[1;36m(APIServer pid=798917)[0;0m DEBUG 11-20 15:30:48.537 [log_time.py:27] Registry inspect model class: Elapsed time 0.0002689 secs
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:30:48.537 [model.py:547] Resolved architecture: Qwen2ForCausalLM
[1;36m(APIServer pid=798917)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:30:48.548 [model.py:1510] Using max model len 32768
[1;36m(APIServer pid=798917)[0;0m DEBUG 11-20 15:30:48.570 [arg_utils.py:1672] Setting max_num_batched_tokens to 8192 for OPENAI_API_SERVER usage context.
[1;36m(APIServer pid=798917)[0;0m DEBUG 11-20 15:30:48.570 [arg_utils.py:1681] Setting max_num_seqs to 1024 for OPENAI_API_SERVER usage context.
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:30:48.649 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.
DEBUG 11-20 15:30:50.939 [__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 11-20 15:30:50.940 [__init__.py:34] Checking if TPU platform is available.
DEBUG 11-20 15:30:50.940 [__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 11-20 15:30:50.940 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:30:50.950 [__init__.py:78] Confirmed CUDA platform is available.
DEBUG 11-20 15:30:50.958 [__init__.py:106] Checking if ROCm platform is available.
DEBUG 11-20 15:30:50.958 [__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 11-20 15:30:50.958 [__init__.py:127] Checking if XPU platform is available.
DEBUG 11-20 15:30:50.958 [__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 11-20 15:30:50.959 [__init__.py:153] Checking if CPU platform is available.
DEBUG 11-20 15:30:50.959 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:30:50.962 [__init__.py:78] Confirmed CUDA platform is available.
INFO 11-20 15:30:50.970 [__init__.py:216] Automatically detected platform cuda.
WARNING 11-20 15:30:52.307 [api_server.py:966] SECURITY WARNING: Development endpoints are enabled! This should NOT be used in production!
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:30:52.412 [core.py:644] Waiting for init message from front-end.
[1;36m(APIServer pid=798917)[0;0m DEBUG 11-20 15:30:52.413 [utils.py:859] HELLO from local core engine process 0.
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:52.413 [core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/66609025-277d-45a5-80f6-59fb594ffdb3'], outputs=['ipc:///tmp/8da98e43-028a-426e-beba-acda549cb258'], coordinator_input=None, coordinator_output=None, frontend_stats_publish_address=None), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 0, '_data_parallel_master_port_list': [], 'data_parallel_size': 1})
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:52.413 [core.py:487] Has DP Coordinator: False, stats publish address: None
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:52.416 [__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:52.416 [__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:52.416 [__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:30:52.417 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='../models/qwen2.5-3b', speculative_config=None, tokenizer='../models/qwen2.5-3b', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=../models/qwen2.5-3b, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:53.527 [decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:53.739 [decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:53.739 [decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:53.841 [__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fdbd4da6190>
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:53.972 [parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://131.234.187.203:54193 backend=nccl
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:54.006 [parallel_state.py:1083] Detected 1 nodes in the distributed environment
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:30:54.009 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=799185)[0;0m WARNING 11-20 15:30:54.208 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:54.214 [__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:30:54.246 [gpu_model_runner.py:2602] Starting to load model ../models/qwen2.5-3b...
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:30:54.446 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:30:54.501 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:54.550 [backends.py:42] Using InductorAdaptor
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:54.565 [compilation.py:649] enabled custom ops: Counter()
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:54.565 [compilation.py:650] disabled custom ops: Counter({'rms_norm': 73, 'column_parallel_linear': 72, 'row_parallel_linear': 72, 'silu_and_mul': 36, 'vocab_parallel_embedding': 1, 'rotary_embedding': 1, 'logits_processor': 1})
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:54.565 [base_loader.py:48] Loading weights on cuda ...
[1;36m(EngineCore_DP0 pid=799185)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=799185)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  4.21it/s]
[1;36m(EngineCore_DP0 pid=799185)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.63it/s]
[1;36m(EngineCore_DP0 pid=799185)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.79it/s]
[1;36m(EngineCore_DP0 pid=799185)[0;0m 
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:30:55.399 [default_loader.py:267] Loading weights took 0.83 seconds
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:30:55.792 [gpu_model_runner.py:2653] Model loading took 5.7916 GiB and 0.957197 seconds
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:55.986 [decorators.py:256] Start compiling function <code object forward at 0x2f16bd60, file "/local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 341>
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] Traced files (to be considered for compilation cache):
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/torch/_dynamo/polyfills/__init__.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/torch/nn/modules/container.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/attention/layer.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/distributed/communication_op.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/distributed/parallel_state.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/custom_op.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/activation.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/layernorm.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/linear.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/rotary_embedding/base.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/rotary_embedding/common.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/utils.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:30:59.372 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/platforms/interface.py
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:30:59.683 [backends.py:548] Using cache directory: /local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:30:59.684 [backends.py:559] Dynamo bytecode transform time: 3.70 s
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.178 [backends.py:127] Directly load the 0-th graph for dynamic shape from inductor via handle ('f4zn7nys6zuglogyh3ak3d6jl4mqbzcobphiyhuiotqjfshtmbyg', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/k2/ck2pa66pf4qdtnmvzqs32b2pnkx3rjdofjtdveh6mgg62qchvkka.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.212 [backends.py:127] Directly load the 1-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.244 [backends.py:127] Directly load the 2-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.276 [backends.py:127] Directly load the 3-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.307 [backends.py:127] Directly load the 4-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.339 [backends.py:127] Directly load the 5-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.370 [backends.py:127] Directly load the 6-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.402 [backends.py:127] Directly load the 7-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.433 [backends.py:127] Directly load the 8-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.465 [backends.py:127] Directly load the 9-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.496 [backends.py:127] Directly load the 10-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.528 [backends.py:127] Directly load the 11-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.559 [backends.py:127] Directly load the 12-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.591 [backends.py:127] Directly load the 13-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.622 [backends.py:127] Directly load the 14-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.654 [backends.py:127] Directly load the 15-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.685 [backends.py:127] Directly load the 16-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.717 [backends.py:127] Directly load the 17-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.748 [backends.py:127] Directly load the 18-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.780 [backends.py:127] Directly load the 19-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.811 [backends.py:127] Directly load the 20-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.842 [backends.py:127] Directly load the 21-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.874 [backends.py:127] Directly load the 22-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.906 [backends.py:127] Directly load the 23-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.937 [backends.py:127] Directly load the 24-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:00.968 [backends.py:127] Directly load the 25-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.000 [backends.py:127] Directly load the 26-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.031 [backends.py:127] Directly load the 27-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.063 [backends.py:127] Directly load the 28-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.095 [backends.py:127] Directly load the 29-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.127 [backends.py:127] Directly load the 30-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.158 [backends.py:127] Directly load the 31-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.190 [backends.py:127] Directly load the 32-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.221 [backends.py:127] Directly load the 33-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.253 [backends.py:127] Directly load the 34-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.284 [backends.py:127] Directly load the 35-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:01.296 [backends.py:127] Directly load the 36-th graph for dynamic shape from inductor via handle ('ffikq2ptajgvmx4re6ssmyj2aacncir5qasy2imeswvalxonvcl7', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/th/cthyymxxwpvo2rut5ph6ohvl4xoaowjozgxuwzokakzkk5rbytt4.py')
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:31:01.296 [backends.py:164] Directly load the compiled graph(s) for dynamic shape from the cache, took 1.139 s
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:31:01.775 [monitor.py:34] torch.compile takes 3.70 s in total
[1;36m(APIServer pid=798917)[0;0m DEBUG 11-20 15:31:02.416 [utils.py:776] Waiting for 1 local, 0 remote core engine proc(s) to start.
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:02.485 [gpu_worker.py:284] Initial free memory: 92.48 GiB; Requested memory: 0.90 (util), 83.78 GiB
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:02.485 [gpu_worker.py:291] Free memory after profiling: 86.39 GiB (total), 77.69 GiB (within requested)
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:02.485 [gpu_worker.py:297] Memory profiling takes 6.50 seconds. Total non KV cache memory: 11.51GiB; torch peak memory increase: 5.58GiB; non-torch forward increase memory: 0.13GiB; weights memory: 5.79GiB.
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:31:02.485 [gpu_worker.py:298] Available KV cache memory: 72.27 GiB
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:31:02.732 [kv_cache_utils.py:1087] GPU KV cache size: 2,105,040 tokens
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:31:02.732 [kv_cache_utils.py:1091] Maximum concurrency for 32,768 tokens per request: 64.24x
[1;36m(EngineCore_DP0 pid=799185)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.018 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=512, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.057 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=504, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.092 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=496, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 3/67 [00:00<00:02, 24.38it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.127 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=488, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.168 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=480, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.204 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=472, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 6/67 [00:00<00:02, 25.77it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.241 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=464, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.280 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=456, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.320 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=448, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–Ž        | 9/67 [00:00<00:02, 25.86it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.356 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=440, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.395 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=432, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.432 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=424, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 12/67 [00:00<00:02, 26.17it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.469 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=416, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.509 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=408, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.546 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=400, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:00<00:01, 26.22it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.581 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=392, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.623 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=384, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.660 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=376, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:00<00:01, 26.22it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.695 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=368, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.736 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=360, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.774 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=352, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:00<00:01, 26.21it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.812 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=344, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.853 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=336, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.892 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=328, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:00<00:01, 26.01it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.932 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=320, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:03.971 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=312, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.008 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=304, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:01<00:01, 25.86it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.047 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=296, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.089 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=288, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.128 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=280, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:01<00:01, 25.57it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.167 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=272, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.211 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=264, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.253 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=256, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:01<00:01, 25.08it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.293 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=248, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.337 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=240, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.375 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=232, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:01<00:01, 24.88it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.418 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=224, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.461 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=216, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.504 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=208, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:01<00:01, 24.38it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.544 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=200, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.590 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=192, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.630 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=184, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:01<00:01, 24.15it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.674 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=176, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.718 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=168, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.762 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=160, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:01<00:00, 23.72it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.803 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=152, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.849 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=144, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.889 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=136, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:01<00:00, 23.64it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.938 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=128, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:04.984 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=120, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.030 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=112, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:02<00:00, 22.88it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.076 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=104, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.124 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=96, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.169 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=88, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:02<00:00, 22.52it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.216 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=80, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.263 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=72, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.307 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=64, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:02<00:00, 22.16it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.350 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=56, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.395 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=48, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.438 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=40, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:02<00:00, 22.43it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.483 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=32, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.526 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=24, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.571 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=16, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:02<00:00, 22.44it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.611 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=8, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.648 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=4, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.685 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=2, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:02<00:00, 23.44it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.730 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=1, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:02<00:00, 24.20it/s]
[1;36m(EngineCore_DP0 pid=799185)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.781 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=512, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.809 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=504, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.834 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=496, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.860 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=488, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):   6%|â–Œ         | 4/67 [00:00<00:01, 35.82it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.885 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=480, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.910 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=472, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.935 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=464, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.961 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=456, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  12%|â–ˆâ–        | 8/67 [00:00<00:01, 37.92it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:05.986 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=448, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.011 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=440, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.036 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=432, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.061 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=424, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  18%|â–ˆâ–Š        | 12/67 [00:00<00:01, 38.79it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.086 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=416, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.111 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=408, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.136 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=400, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.162 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=392, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  24%|â–ˆâ–ˆâ–       | 16/67 [00:00<00:01, 39.10it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.187 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=384, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.212 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=376, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.237 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=368, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.262 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=360, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.287 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=352, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:00<00:01, 39.51it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.312 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=344, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.338 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=336, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.363 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=328, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.388 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=320, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:00<00:01, 39.50it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.413 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=312, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.439 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=304, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.464 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=296, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.488 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=288, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:00<00:00, 39.65it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.513 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=280, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.539 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=272, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.565 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=264, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.591 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=256, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:00<00:00, 39.49it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.616 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=248, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.642 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=240, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.667 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=232, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.692 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=224, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:00<00:00, 39.29it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.719 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=216, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.745 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=208, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.770 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=200, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.795 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=192, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:01<00:00, 39.32it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.821 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=184, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.846 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=176, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.871 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=168, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.896 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=160, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:01<00:00, 39.31it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.922 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=152, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.948 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=144, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.973 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=136, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:06.998 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=128, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:01<00:00, 39.43it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.023 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=120, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.048 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=112, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.073 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=104, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.100 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=96, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:01<00:00, 39.36it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.125 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=88, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.150 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=80, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.175 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=72, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.200 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=64, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.225 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=56, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:01<00:00, 39.60it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.250 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=48, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.275 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=40, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.301 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=32, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.325 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=24, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:01<00:00, 39.64it/s][1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.350 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=16, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.375 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=8, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.399 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=4, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.424 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=2, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.448 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=1, uniform_decode=True))
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 39.90it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 39.39it/s]
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:31:07.729 [gpu_model_runner.py:3480] Graph capturing finished in 5 secs, took 0.69 GiB
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:07.729 [gpu_worker.py:393] Free memory on device (92.48/93.09 GiB) on startup. Desired GPU memory utilization is (0.9, 83.78 GiB). Actual usage is 5.79 GiB for weight, 5.58 GiB for peak activation, 0.13 GiB for non-torch memory, and 0.69 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=76700961075` (71.43 GiB) to fit into requested memory, or `--kv-cache-memory=86047069696` (80.14 GiB) to fully utilize gpu memory. Current kv cache memory in use is 72.27 GiB.
[1;36m(EngineCore_DP0 pid=799185)[0;0m INFO 11-20 15:31:07.751 [core.py:210] init engine (profile, create kv cache, warmup model) took 11.96 seconds
[1;36m(APIServer pid=798917)[0;0m DEBUG 11-20 15:31:08.040 [utils.py:859] READY from local core engine process 0.
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.226 [loggers.py:147] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 131565
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:08.318 [core.py:737] EngineCore waiting for work.
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:08.318 [core.py:737] EngineCore waiting for work.
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:08.359 [core.py:737] EngineCore waiting for work.
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.359 [api_server.py:1634] Supported_tasks: ['generate']
[1;36m(APIServer pid=798917)[0;0m WARNING 11-20 15:31:08.361 [model.py:1389] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.361 [serving_responses.py:137] Using default chat sampling params from model: {'max_tokens': 2048}
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.362 [serving_chat.py:139] Using default chat sampling params from model: {'max_tokens': 2048}
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.364 [serving_completion.py:76] Using default completion sampling params from model: {'max_tokens': 2048}
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.364 [api_server.py:1912] Starting vLLM API server 0 on http://0.0.0.0:8501
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.364 [launcher.py:34] Available routes are:
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.364 [launcher.py:42] Route: /openapi.json, Methods: HEAD, GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.365 [launcher.py:42] Route: /docs, Methods: HEAD, GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.365 [launcher.py:42] Route: /docs/oauth2-redirect, Methods: HEAD, GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.365 [launcher.py:42] Route: /redoc, Methods: HEAD, GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.365 [launcher.py:42] Route: /health, Methods: GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.365 [launcher.py:42] Route: /load, Methods: GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.366 [launcher.py:42] Route: /ping, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.366 [launcher.py:42] Route: /ping, Methods: GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.366 [launcher.py:42] Route: /tokenize, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.366 [launcher.py:42] Route: /detokenize, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.366 [launcher.py:42] Route: /v1/models, Methods: GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.366 [launcher.py:42] Route: /version, Methods: GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.367 [launcher.py:42] Route: /v1/responses, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.367 [launcher.py:42] Route: /v1/responses/{response_id}, Methods: GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.367 [launcher.py:42] Route: /v1/responses/{response_id}/cancel, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.367 [launcher.py:42] Route: /v1/chat/completions, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.367 [launcher.py:42] Route: /v1/completions, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.367 [launcher.py:42] Route: /v1/embeddings, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.368 [launcher.py:42] Route: /pooling, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.368 [launcher.py:42] Route: /classify, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.368 [launcher.py:42] Route: /score, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.368 [launcher.py:42] Route: /v1/score, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.368 [launcher.py:42] Route: /v1/audio/transcriptions, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.368 [launcher.py:42] Route: /v1/audio/translations, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.369 [launcher.py:42] Route: /rerank, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.369 [launcher.py:42] Route: /v1/rerank, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.369 [launcher.py:42] Route: /v2/rerank, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.369 [launcher.py:42] Route: /server_info, Methods: GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.369 [launcher.py:42] Route: /reset_prefix_cache, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.369 [launcher.py:42] Route: /sleep, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.370 [launcher.py:42] Route: /wake_up, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.370 [launcher.py:42] Route: /is_sleeping, Methods: GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.370 [launcher.py:42] Route: /collective_rpc, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.370 [launcher.py:42] Route: /scale_elastic_ep, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.370 [launcher.py:42] Route: /is_scaling_elastic_ep, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.370 [launcher.py:42] Route: /invocations, Methods: POST
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:08.371 [launcher.py:42] Route: /metrics, Methods: GET
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:09.148 [api_server.py:1024] check whether the engine is sleeping
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:09.149 [core.py:737] EngineCore waiting for work.
[1;36m(APIServer pid=798917)[0;0m INFO 11-20 15:31:09.219 [api_server.py:1024] check whether the engine is sleeping
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:09.220 [core.py:737] EngineCore waiting for work.
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:09.232 [core.py:743] EngineCore loop active.
[1;36m(EngineCore_DP0 pid=799185)[0;0m DEBUG 11-20 15:31:10.218 [core.py:737] EngineCore waiting for work.
DEBUG 11-20 15:31:34.347 [__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 11-20 15:31:34.348 [__init__.py:34] Checking if TPU platform is available.
DEBUG 11-20 15:31:34.348 [__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 11-20 15:31:34.348 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:31:34.359 [__init__.py:78] Confirmed CUDA platform is available.
DEBUG 11-20 15:31:34.366 [__init__.py:106] Checking if ROCm platform is available.
DEBUG 11-20 15:31:34.366 [__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 11-20 15:31:34.366 [__init__.py:127] Checking if XPU platform is available.
DEBUG 11-20 15:31:34.366 [__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 11-20 15:31:34.366 [__init__.py:153] Checking if CPU platform is available.
DEBUG 11-20 15:31:34.367 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:31:34.369 [__init__.py:78] Confirmed CUDA platform is available.
INFO 11-20 15:31:34.377 [__init__.py:216] Automatically detected platform cuda.
WARNING 11-20 15:31:35.695 [api_server.py:966] SECURITY WARNING: Development endpoints are enabled! This should NOT be used in production!
DEBUG 11-20 15:31:35.699 [utils.py:163] Setting VLLM_WORKER_MULTIPROC_METHOD to 'spawn'
DEBUG 11-20 15:31:35.703 [__init__.py:36] Available plugins for group vllm.general_plugins:
DEBUG 11-20 15:31:35.703 [__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
DEBUG 11-20 15:31:35.703 [__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:35.788 [api_server.py:1839] vLLM API server version 0.11.0
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:35.790 [utils.py:233] non-default args: {'port': 8501, 'model': '../models/qwen2.5-3b'}
[1;36m(APIServer pid=800462)[0;0m DEBUG 11-20 15:31:35.793 [registry.py:498] Loaded model info for class vllm.model_executor.models.qwen2.Qwen2ForCausalLM from cache
[1;36m(APIServer pid=800462)[0;0m DEBUG 11-20 15:31:35.794 [log_time.py:27] Registry inspect model class: Elapsed time 0.0002819 secs
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:35.794 [model.py:547] Resolved architecture: Qwen2ForCausalLM
[1;36m(APIServer pid=800462)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:35.805 [model.py:1510] Using max model len 32768
[1;36m(APIServer pid=800462)[0;0m DEBUG 11-20 15:31:35.827 [arg_utils.py:1672] Setting max_num_batched_tokens to 8192 for OPENAI_API_SERVER usage context.
[1;36m(APIServer pid=800462)[0;0m DEBUG 11-20 15:31:35.827 [arg_utils.py:1681] Setting max_num_seqs to 1024 for OPENAI_API_SERVER usage context.
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:35.907 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.
DEBUG 11-20 15:31:38.189 [__init__.py:28] No plugins for group vllm.platform_plugins found.
DEBUG 11-20 15:31:38.189 [__init__.py:34] Checking if TPU platform is available.
DEBUG 11-20 15:31:38.190 [__init__.py:52] TPU platform is not available because: No module named 'libtpu'
DEBUG 11-20 15:31:38.190 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:31:38.200 [__init__.py:78] Confirmed CUDA platform is available.
DEBUG 11-20 15:31:38.208 [__init__.py:106] Checking if ROCm platform is available.
DEBUG 11-20 15:31:38.208 [__init__.py:120] ROCm platform is not available because: No module named 'amdsmi'
DEBUG 11-20 15:31:38.208 [__init__.py:127] Checking if XPU platform is available.
DEBUG 11-20 15:31:38.208 [__init__.py:146] XPU platform is not available because: No module named 'intel_extension_for_pytorch'
DEBUG 11-20 15:31:38.208 [__init__.py:153] Checking if CPU platform is available.
DEBUG 11-20 15:31:38.209 [__init__.py:58] Checking if CUDA platform is available.
DEBUG 11-20 15:31:38.211 [__init__.py:78] Confirmed CUDA platform is available.
INFO 11-20 15:31:38.219 [__init__.py:216] Automatically detected platform cuda.
WARNING 11-20 15:31:39.558 [api_server.py:966] SECURITY WARNING: Development endpoints are enabled! This should NOT be used in production!
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:39.661 [core.py:644] Waiting for init message from front-end.
[1;36m(APIServer pid=800462)[0;0m DEBUG 11-20 15:31:39.662 [utils.py:859] HELLO from local core engine process 0.
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:39.662 [core.py:652] Received init message: EngineHandshakeMetadata(addresses=EngineZmqAddresses(inputs=['ipc:///tmp/0108541f-8128-4bfe-90a0-886f9dedecaf'], outputs=['ipc:///tmp/8d03afee-e73a-479f-a56d-320dfb2775c7'], coordinator_input=None, coordinator_output=None, frontend_stats_publish_address=None), parallel_config={'data_parallel_master_ip': '127.0.0.1', 'data_parallel_master_port': 0, '_data_parallel_master_port_list': [], 'data_parallel_size': 1})
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:39.662 [core.py:487] Has DP Coordinator: False, stats publish address: None
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:39.666 [__init__.py:36] Available plugins for group vllm.general_plugins:
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:39.666 [__init__.py:38] - lora_filesystem_resolver -> vllm.plugins.lora_resolvers.filesystem_resolver:register_filesystem_resolver
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:39.666 [__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:39.666 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='../models/qwen2.5-3b', speculative_config=None, tokenizer='../models/qwen2.5-3b', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=../models/qwen2.5-3b, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:40.770 [decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.deepseek_v2.DeepseekV2Model'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:40.982 [decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama.LlamaModel'>: ['input_ids', 'positions', 'intermediate_tensors', 'inputs_embeds']
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:40.983 [decorators.py:155] Inferred dynamic dimensions for forward method of <class 'vllm.model_executor.models.llama_eagle3.LlamaModel'>: ['input_ids', 'positions', 'hidden_states']
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:41.085 [__init__.py:3188] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7efe0801f2d0>
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:41.215 [parallel_state.py:1029] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://131.234.187.203:50407 backend=nccl
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:41.238 [parallel_state.py:1083] Detected 1 nodes in the distributed environment
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:41.242 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=800740)[0;0m WARNING 11-20 15:31:41.438 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:41.444 [__init__.py:57] No logitsprocs plugins installed (group vllm.logits_processors).
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:41.476 [gpu_model_runner.py:2602] Starting to load model ../models/qwen2.5-3b...
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:41.674 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:41.729 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:41.777 [backends.py:42] Using InductorAdaptor
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:41.793 [compilation.py:649] enabled custom ops: Counter()
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:41.793 [compilation.py:650] disabled custom ops: Counter({'rms_norm': 73, 'column_parallel_linear': 72, 'row_parallel_linear': 72, 'silu_and_mul': 36, 'vocab_parallel_embedding': 1, 'rotary_embedding': 1, 'logits_processor': 1})
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:41.794 [base_loader.py:48] Loading weights on cuda ...
[1;36m(EngineCore_DP0 pid=800740)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=800740)[0;0m Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  4.26it/s]
[1;36m(EngineCore_DP0 pid=800740)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.65it/s]
[1;36m(EngineCore_DP0 pid=800740)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.81it/s]
[1;36m(EngineCore_DP0 pid=800740)[0;0m 
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:42.623 [default_loader.py:267] Loading weights took 0.83 seconds
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:43.010 [gpu_model_runner.py:2653] Model loading took 5.7916 GiB and 0.952834 seconds
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:43.199 [decorators.py:256] Start compiling function <code object forward at 0x1cc00a10, file "/local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py", line 341>
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] Traced files (to be considered for compilation cache):
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/torch/_dynamo/polyfills/__init__.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/torch/nn/modules/container.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/attention/layer.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/distributed/communication_op.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/distributed/parallel_state.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/custom_op.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/activation.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/layernorm.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/linear.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/rotary_embedding/base.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/rotary_embedding/common.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/utils.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/model_executor/models/qwen2.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:46.579 [backends.py:501] /local/huzaifa/workspace/vLLM/vllm-serverless-optimization/.vllm/lib/python3.11/site-packages/vllm/platforms/interface.py
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:46.889 [backends.py:548] Using cache directory: /local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:46.890 [backends.py:559] Dynamo bytecode transform time: 3.69 s
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.378 [backends.py:127] Directly load the 0-th graph for dynamic shape from inductor via handle ('f4zn7nys6zuglogyh3ak3d6jl4mqbzcobphiyhuiotqjfshtmbyg', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/k2/ck2pa66pf4qdtnmvzqs32b2pnkx3rjdofjtdveh6mgg62qchvkka.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.412 [backends.py:127] Directly load the 1-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.443 [backends.py:127] Directly load the 2-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.475 [backends.py:127] Directly load the 3-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.507 [backends.py:127] Directly load the 4-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.538 [backends.py:127] Directly load the 5-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.570 [backends.py:127] Directly load the 6-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.601 [backends.py:127] Directly load the 7-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.632 [backends.py:127] Directly load the 8-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.664 [backends.py:127] Directly load the 9-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.695 [backends.py:127] Directly load the 10-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.727 [backends.py:127] Directly load the 11-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.758 [backends.py:127] Directly load the 12-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.790 [backends.py:127] Directly load the 13-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.821 [backends.py:127] Directly load the 14-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.853 [backends.py:127] Directly load the 15-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.884 [backends.py:127] Directly load the 16-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.915 [backends.py:127] Directly load the 17-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.947 [backends.py:127] Directly load the 18-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:47.978 [backends.py:127] Directly load the 19-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.010 [backends.py:127] Directly load the 20-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.041 [backends.py:127] Directly load the 21-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.072 [backends.py:127] Directly load the 22-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.104 [backends.py:127] Directly load the 23-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.135 [backends.py:127] Directly load the 24-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.167 [backends.py:127] Directly load the 25-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.198 [backends.py:127] Directly load the 26-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.229 [backends.py:127] Directly load the 27-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.260 [backends.py:127] Directly load the 28-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.292 [backends.py:127] Directly load the 29-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.323 [backends.py:127] Directly load the 30-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.355 [backends.py:127] Directly load the 31-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.386 [backends.py:127] Directly load the 32-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.417 [backends.py:127] Directly load the 33-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.449 [backends.py:127] Directly load the 34-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.480 [backends.py:127] Directly load the 35-th graph for dynamic shape from inductor via handle ('f5lqixzflhgdgxvpftwk6n3vlfv7r6m546txm6hdmjctakwlcx6q', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/cx/ccxv3e6sfjpd3oevkemnkff5ejbnaffocqekvpowcikbpftq4m6y.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:48.492 [backends.py:127] Directly load the 36-th graph for dynamic shape from inductor via handle ('ffikq2ptajgvmx4re6ssmyj2aacncir5qasy2imeswvalxonvcl7', '/local/huzaifa/.cache/vllm/torch_compile_cache/1922fc3f3b/rank_0_0/inductor_cache/th/cthyymxxwpvo2rut5ph6ohvl4xoaowjozgxuwzokakzkk5rbytt4.py')
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:48.492 [backends.py:164] Directly load the compiled graph(s) for dynamic shape from the cache, took 1.135 s
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:48.972 [monitor.py:34] torch.compile takes 3.69 s in total
[1;36m(APIServer pid=800462)[0;0m DEBUG 11-20 15:31:49.672 [utils.py:776] Waiting for 1 local, 0 remote core engine proc(s) to start.
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:49.699 [gpu_worker.py:284] Initial free memory: 92.48 GiB; Requested memory: 0.90 (util), 83.78 GiB
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:49.699 [gpu_worker.py:291] Free memory after profiling: 86.39 GiB (total), 77.69 GiB (within requested)
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:49.699 [gpu_worker.py:297] Memory profiling takes 6.50 seconds. Total non KV cache memory: 11.51GiB; torch peak memory increase: 5.58GiB; non-torch forward increase memory: 0.13GiB; weights memory: 5.79GiB.
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:49.700 [gpu_worker.py:298] Available KV cache memory: 72.27 GiB
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:49.953 [kv_cache_utils.py:1087] GPU KV cache size: 2,105,040 tokens
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:49.953 [kv_cache_utils.py:1091] Maximum concurrency for 32,768 tokens per request: 64.24x
[1;36m(EngineCore_DP0 pid=800740)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.244 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=512, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.283 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=504, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.316 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=496, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 3/67 [00:00<00:02, 25.05it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.350 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=488, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.390 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=480, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.424 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=472, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 6/67 [00:00<00:02, 26.63it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.459 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=464, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.497 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=456, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.535 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=448, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–Ž        | 9/67 [00:00<00:02, 26.79it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.571 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=440, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.607 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=432, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.642 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=424, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 12/67 [00:00<00:02, 27.22it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.678 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=416, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.716 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=408, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.751 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=400, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:00<00:01, 27.29it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.785 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=392, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.826 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=384, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.862 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=376, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:00<00:01, 27.28it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.896 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=368, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.935 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=360, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:50.972 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=352, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:00<00:01, 27.24it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.008 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=344, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.048 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=336, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.085 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=328, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:00<00:01, 26.99it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.124 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=320, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.162 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=312, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.197 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=304, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:01<00:01, 26.84it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.235 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=296, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.276 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=288, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.313 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=280, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:01<00:01, 26.54it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.351 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=272, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.394 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=264, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.434 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=256, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:01<00:01, 25.97it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.473 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=248, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.515 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=240, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.552 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=232, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:01<00:01, 25.79it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.594 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=224, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.635 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=216, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.677 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=208, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:01<00:01, 25.27it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.715 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=200, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.759 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=192, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.798 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=184, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:01<00:00, 25.06it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.839 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=176, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.882 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=168, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.925 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=160, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:01<00:00, 24.58it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:51.965 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=152, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.009 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=144, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.048 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=136, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:01<00:00, 24.48it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.095 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=128, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.140 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=120, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.185 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=112, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:01<00:00, 23.66it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.229 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=104, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.276 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=96, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.319 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=88, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:02<00:00, 23.25it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.366 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=80, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.412 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=72, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.454 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=64, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:02<00:00, 22.84it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.495 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=56, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.540 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=48, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.581 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=40, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:02<00:00, 23.15it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.624 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=32, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.667 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=24, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.710 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=16, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:02<00:00, 23.16it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.748 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=8, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.784 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=4, uniform_decode=False))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.819 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=2, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:02<00:00, 24.29it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.862 [cuda_graph.py:136] Capturing a cudagraph on (PIECEWISE,BatchDescriptor(num_tokens=1, uniform_decode=False))
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:02<00:00, 25.06it/s]
[1;36m(EngineCore_DP0 pid=800740)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.911 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=512, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.939 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=504, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.964 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=496, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:52.989 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=488, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):   6%|â–Œ         | 4/67 [00:00<00:01, 36.12it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.015 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=480, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.039 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=472, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.064 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=464, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.089 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=456, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.115 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=448, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  13%|â–ˆâ–Ž        | 9/67 [00:00<00:01, 38.49it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.140 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=440, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.164 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=432, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.189 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=424, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.214 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=416, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.239 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=408, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  21%|â–ˆâ–ˆ        | 14/67 [00:00<00:01, 39.30it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.264 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=400, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.290 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=392, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.315 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=384, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.339 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=376, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:00<00:01, 39.53it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.364 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=368, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.389 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=360, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.414 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=352, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.439 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=344, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 22/67 [00:00<00:01, 39.61it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.465 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=336, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.489 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=328, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.514 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=320, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.539 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=312, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.564 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=304, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:00<00:01, 39.84it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.589 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=296, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.613 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=288, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.638 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=280, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.664 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=272, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:00<00:00, 39.89it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.689 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=264, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.715 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=256, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.740 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=248, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.766 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=240, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:00<00:00, 39.75it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.791 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=232, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.816 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=224, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.843 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=216, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.868 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=208, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:00<00:00, 39.54it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.893 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=200, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.918 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=192, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.943 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=184, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.969 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=176, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:01<00:00, 39.58it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:53.994 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=168, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.019 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=160, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.045 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=152, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.070 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=144, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:01<00:00, 39.56it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.095 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=136, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.120 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=128, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.145 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=120, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.170 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=112, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.194 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=104, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:01<00:00, 39.65it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.221 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=96, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.246 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=88, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.271 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=80, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.295 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=72, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.320 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=64, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:01<00:00, 39.88it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.344 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=56, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.369 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=48, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.394 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=40, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.420 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=32, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:01<00:00, 39.89it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.444 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=24, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.469 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=16, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.494 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=8, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.518 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=4, uniform_decode=True))
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.542 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=2, uniform_decode=True))
Capturing CUDA graphs (decode, FULL):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:01<00:00, 40.28it/s][1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.566 [cuda_graph.py:136] Capturing a cudagraph on (FULL,BatchDescriptor(num_tokens=1, uniform_decode=True))
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 39.69it/s]
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:54.853 [gpu_model_runner.py:3480] Graph capturing finished in 5 secs, took 0.69 GiB
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:54.853 [gpu_worker.py:393] Free memory on device (92.48/93.09 GiB) on startup. Desired GPU memory utilization is (0.9, 83.78 GiB). Actual usage is 5.79 GiB for weight, 5.58 GiB for peak activation, 0.13 GiB for non-torch memory, and 0.69 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=76700961075` (71.43 GiB) to fit into requested memory, or `--kv-cache-memory=86047069696` (80.14 GiB) to fully utilize gpu memory. Current kv cache memory in use is 72.27 GiB.
[1;36m(EngineCore_DP0 pid=800740)[0;0m INFO 11-20 15:31:54.875 [core.py:210] init engine (profile, create kv cache, warmup model) took 11.86 seconds
[1;36m(APIServer pid=800462)[0;0m DEBUG 11-20 15:31:55.166 [utils.py:859] READY from local core engine process 0.
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.352 [loggers.py:147] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 131565
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:55.448 [core.py:737] EngineCore waiting for work.
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:55.449 [core.py:737] EngineCore waiting for work.
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:55.488 [core.py:737] EngineCore waiting for work.
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.489 [api_server.py:1634] Supported_tasks: ['generate']
[1;36m(APIServer pid=800462)[0;0m WARNING 11-20 15:31:55.490 [model.py:1389] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.491 [serving_responses.py:137] Using default chat sampling params from model: {'max_tokens': 2048}
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.492 [serving_chat.py:139] Using default chat sampling params from model: {'max_tokens': 2048}
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.493 [serving_completion.py:76] Using default completion sampling params from model: {'max_tokens': 2048}
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.493 [api_server.py:1912] Starting vLLM API server 0 on http://0.0.0.0:8501
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.493 [launcher.py:34] Available routes are:
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.494 [launcher.py:42] Route: /openapi.json, Methods: HEAD, GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.494 [launcher.py:42] Route: /docs, Methods: HEAD, GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.494 [launcher.py:42] Route: /docs/oauth2-redirect, Methods: HEAD, GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.494 [launcher.py:42] Route: /redoc, Methods: HEAD, GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.494 [launcher.py:42] Route: /health, Methods: GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.495 [launcher.py:42] Route: /load, Methods: GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.495 [launcher.py:42] Route: /ping, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.495 [launcher.py:42] Route: /ping, Methods: GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.495 [launcher.py:42] Route: /tokenize, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.495 [launcher.py:42] Route: /detokenize, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.495 [launcher.py:42] Route: /v1/models, Methods: GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.496 [launcher.py:42] Route: /version, Methods: GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.496 [launcher.py:42] Route: /v1/responses, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.496 [launcher.py:42] Route: /v1/responses/{response_id}, Methods: GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.496 [launcher.py:42] Route: /v1/responses/{response_id}/cancel, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.496 [launcher.py:42] Route: /v1/chat/completions, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.496 [launcher.py:42] Route: /v1/completions, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.497 [launcher.py:42] Route: /v1/embeddings, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.497 [launcher.py:42] Route: /pooling, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.497 [launcher.py:42] Route: /classify, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.497 [launcher.py:42] Route: /score, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.497 [launcher.py:42] Route: /v1/score, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.497 [launcher.py:42] Route: /v1/audio/transcriptions, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.498 [launcher.py:42] Route: /v1/audio/translations, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.498 [launcher.py:42] Route: /rerank, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.498 [launcher.py:42] Route: /v1/rerank, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.498 [launcher.py:42] Route: /v2/rerank, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.498 [launcher.py:42] Route: /server_info, Methods: GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.498 [launcher.py:42] Route: /reset_prefix_cache, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.499 [launcher.py:42] Route: /sleep, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.499 [launcher.py:42] Route: /wake_up, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.499 [launcher.py:42] Route: /is_sleeping, Methods: GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.499 [launcher.py:42] Route: /collective_rpc, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.499 [launcher.py:42] Route: /scale_elastic_ep, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.499 [launcher.py:42] Route: /is_scaling_elastic_ep, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.499 [launcher.py:42] Route: /invocations, Methods: POST
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:55.500 [launcher.py:42] Route: /metrics, Methods: GET
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:56.402 [api_server.py:1024] check whether the engine is sleeping
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:56.403 [core.py:737] EngineCore waiting for work.
[1;36m(APIServer pid=800462)[0;0m INFO 11-20 15:31:56.472 [api_server.py:1024] check whether the engine is sleeping
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:56.473 [core.py:737] EngineCore waiting for work.
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:56.484 [core.py:743] EngineCore loop active.
[1;36m(EngineCore_DP0 pid=800740)[0;0m DEBUG 11-20 15:31:57.470 [core.py:737] EngineCore waiting for work.
